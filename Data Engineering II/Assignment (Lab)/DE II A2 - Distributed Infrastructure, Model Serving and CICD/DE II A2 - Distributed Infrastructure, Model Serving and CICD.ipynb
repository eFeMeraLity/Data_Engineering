{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DE II A2 - Distributed Infrastructure, Model Serving and CI/CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The lab assignment covers the practical part of the discussed concepts of dynamic contextualization and model serving in a scalable production environment and reliable continuous integration and development process. The lab consists of four tasks and one optional task. First three tasks are compulsory, forth task is a bonus task and optional task does not have any points.\\\n",
    "实验作业涵盖了所讨论的dynamic contextualization概念的实践部分，以及在可伸缩生产环境和可靠的持续集成和开发过程中服务的模型。该实验室由四个任务和一个可选任务组成。前三个任务是强制性的，第四个任务是奖励任务，可选任务没有任何分数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important:\n",
    "\n",
    "1. Please terminate VMs once you finish the task.\\\n",
    "任务完成后，请立即终止虚拟机。\n",
    "2. We recommend you to create a VM in SSC and execute all the tasks on that virtual machine. You can run the tasks on your laptops but it may break your local working environment.\\\n",
    "我们建议您在SSC中创建一个虚拟机，并在该虚拟机上执行所有任务。你可以在笔记本电脑上运行这些任务，但这可能会破坏你当地的工作环境。\n",
    "3. For all the tasks, clone the repository: [model_serving](https://github.com/sztoor/model_serving.git)\\\n",
    "对于所有任务，克隆存储库：[model_serving](https://github.com/sztoor/model_serving.git)\n",
    "4. The code for tasks is available in the `model_serving` directory.\\\n",
    "任务的代码可以在`model_serving`目录中找到。\n",
    "\n",
    "```shell\n",
    "- model_serving\n",
    "    -- Single_server_without_docker\n",
    "    -- Single_server_with_docker\n",
    "    -- CI_CD\n",
    "    -- OpenStack-Client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Contextualization\n",
    "\n",
    "Dynamic contextualization is a process of preparing a customized computing environment at runtime. The process is ranging from creating/defining user roles and permissions to updating/installing different packages and initiating services.\\\n",
    "动态上下文化是在运行时准备定制计算环境的过程。这个过程从创建/定义用户角色和权限到更新/安装不同的包和启动服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-1: Single Server Deployment\n",
    "\n",
    "In this task, we will learn how the dynamic contextualization works using Cloud-Init package. For this task, we need to use OpenStack APIs to start a new VM and contextualize it at run time. The contextualization process will setup the following working environment:\\\n",
    "在本任务中，我们将学习动态上下文化是如何工作的，使用Cloud-Init包。对于这个任务，我们需要使用OpenStack APIs来启动一个新的VM，并在运行时将其上下文化。上下文化过程将设置以下工作环境：\n",
    "1. Flask based web application as a frontend server\\\n",
    "基于Flask的web应用作为前端服务器\n",
    "2. Celery and RabbitMQ server for backend server\\\n",
    "Celery和RabbitMQ服务器作为后端服务器\n",
    "3. Model execution environment based on Keras and TensorFlow\\\n",
    "基于Keras和TensorFlow的模型执行环境\n",
    "\n",
    "In case you are not familiar with the above-mentioned packages please read the following links:\\\n",
    "如果你不熟悉上述的包裹，请阅读以下链接：\n",
    "1. Flask Application -> [Welcome to Flask — Flask Documentation (1.1.x)](https://flask.palletsprojects.com/en/1.1.x/)\n",
    "2. Celery and RabbitMQ -> [Getting Started — Celery 5.0.5 documentation](https://docs.celeryproject.org/en/stable/getting-started/)\n",
    "3. Keras and TensorFlow -> [Keras | TensorFlow Core](https://www.tensorflow.org/guide/keras)\n",
    "\n",
    "The process will start when a client sends a new prediction request from the frontend web server. The server will pass the request to the backend Celery environment where running workers in the setup will pick up the task, run the predictions by loading the available model, send back the results and finally frontend server will display the results.\\\n",
    "当client从前端web服务器发送一个新的预测请求时，该进程将启动。服务器将把请求传递给后端Celery环境，在那里运行设置中的工作人员将捡起任务，通过加载可用模型运行预测，返回结果，最后前端服务器将显示结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps for VM contextualization**\n",
    "\n",
    "#### 1. Start a VM from the SSC dashboard and login.\n",
    "\n",
    "* Log into the [SNIC cloud](https://east-1.cloud.snic.se/).\n",
    "* Log in VM:\n",
    "```shell\n",
    "ssh -i /Users/lmf/PycharmProjects/MSc_DS/Important/key_DE.pem ubuntu@130.238.29.126\n",
    "```\n",
    "    * Remove host key in `~/.ssh/known_hosts` to get rid of message `WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!`.\n",
    "    ```shell\n",
    "    vim ~/.ssh/known_hosts\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Clone the git repository.\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/sztoor/model_serving.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Go to the `model_serving/single_server_without_docker/production_server/` directory.\n",
    "\n",
    "The directory contains the code that will run on the production server VM.\\\n",
    "该目录包含将在production服务器VM上运行的代码。\n",
    "\n",
    "Following is the structure of the code:\\\n",
    "以下是代码的结构：\n",
    "* Flask Application based frontend\\\n",
    "基于前端的Flask应用程序\n",
    "    * `app.py`\n",
    "    * `static`\n",
    "    * `templates`\n",
    "* Celery and RabbitMQ setup\\\n",
    "Celery和RabbitMQ设置\n",
    "    * `run_task.py`\n",
    "    * `workerA.py`\n",
    "* Machine learning Model and Data\\\n",
    "机器学习模型和数据\n",
    "    * `model.h5`\n",
    "    * `model.json`\n",
    "    * `pima-indians-diabetes.csv`\n",
    "\n",
    "Open files and understand the application's structure.\\\n",
    "打开文件并理解应用程序的结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Go to the `model_serving/openstack-client/single_node_without_docker_client/` directory.\n",
    "\n",
    "This is the code that we will use to contextualize our production server.\\\n",
    "这是我们将用于上下文化production服务器的代码。\n",
    "\n",
    "The code is based on the following two files:\\\n",
    "该代码基于以下两个文件:\n",
    "\n",
    "* Cloud-Init configuration file\\\n",
    "Cloud-Init配置文件\n",
    "    * `cloud-cfg.txt`\n",
    "* OpenStack python code\\\n",
    "OpenStack python代码\n",
    "    * `start_instance.py`\n",
    "\n",
    "Open the files and understand the steps.\\\n",
    "打开文件并理解其中的步骤。\n",
    "* __NOTE:__ You need to setup variable values in the `start_instance.py` script.\\\n",
    "您需要在`start_instance.py`脚本中设置变量值。\n",
    "```shell\n",
    "cd model_serving/openstack-client/single_node_without_docker_client/\n",
    "vim start_instance.py\n",
    "```\n",
    "Modify `start_instance.py`:\n",
    "```python\n",
    "flavor = \"ssc.medium\"\n",
    "private_net = \"UPPMAX 2020/1-3 Internal IPv4 Network\"\n",
    "floating_ip_pool_name = None\n",
    "floating_ip = None\n",
    "image_name = \"98c10a7f-2587-450b-866c-1266ea0dbe4b\"\n",
    "```\n",
    "    * https://docs.openstack.org/python-novaclient/ocata/ref/v2/servers.html\n",
    "* __Important:__ In order to run this code, you need to have OpenStack API environment running.\\\n",
    "运行此代码需要运行OpenStack API环境。\n",
    "* __NOTE:__ Openstack APIs are only need to be installed on the client VM.\\\n",
    "Openstack API只需要安装在client VM上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Follow the instructions available on the following links:\n",
    "\n",
    "* [OpenStack packages for Ubuntu](https://docs.openstack.org/install-guide/environment-packages-ubuntu.html)\n",
    "```shell\n",
    "# Enable the repository for Ubuntu Cloud Archive\n",
    "sudo add-apt-repository cloud-archive:victoria\n",
    "# Finalize the installation\n",
    "# 1. Upgrade packages on all nodes:\n",
    "sudo -s\n",
    "sudo apt update && apt dist-upgrade\n",
    "# 2. Install the OpenStack client:\n",
    "sudo apt install python3-openstackclient\n",
    "```\n",
    "\n",
    "* [Install the OpenStack command-line clients](http://docs.openstack.org/mitaka/user-guide/common/cli_install_openstack_command_line_clients.html)\n",
    "\n",
    "Download the client tools and API for OpenStack.\\\n",
    "下载OpenStack的客户端工具和API。\n",
    "\n",
    "Download the Runtime Configuration (RC) file (version 3) from the SSC site (Top left frame, `Project` -> `API Access` -> `Download OpenStack RC File`).\\\n",
    "从SSC站点下载Runtime Configuration（RC）文件（版本3）（左上角，`项目` -> `访问API` -> `下载OpenStack RC文件`）。\n",
    "```shell\n",
    "vim DEII_L2_T1-openrc.sh\n",
    "```\n",
    "\n",
    "Set API access password. Go to [SNIC Science Cloud (SSC)](https://cloud.snic.se/), Left frame, under `Services` `Set your API password`.\\\n",
    "设置API访问密码。转到[SNIC Science Cloud (SSC)](https://cloud.snic.se/)，左边，在`SERVICES`下，`Set your API password`。\n",
    "\n",
    "Confirm that your RC file have following environment variables:\\\n",
    "确认你的RC文件有以下环境变量：\n",
    "```shell\n",
    "export OS_USER_DOMAIN_NAME=\"snic\"\n",
    "export OS_IDENTITY_API_VERSION=\"3\"\n",
    "export OS_PROJECT_DOMAIN_NAME=\"snic\"\n",
    "export OS_PROJECT_NAME=\"UPPMAX 2020/1-3\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Set the environment variables by sourcing the RC-file in the client VM.\n",
    "通过在client VM中source RC文件来设置环境变量。\n",
    "\n",
    "```shell\n",
    "# source <project_name>_openrc.sh\n",
    "source DEII_L2_T1-openrc.sh\n",
    "```\n",
    "__NOTE:__ You need to enter the API access password.\\\n",
    "需要输入API访问密码。\n",
    "\n",
    "The successful execution of the following commands will confirm that you have the correct packages available on your client VM:\\\n",
    "成功执行以下命令将确认您的client VM上有可用的正确软件包:\n",
    "```shell\n",
    "openstack server list\n",
    "openstack image list\n",
    "```\n",
    "\n",
    "For the API communication, we need following extra packages:\\\n",
    "对于API通信，我们需要以下额外的包:\n",
    "```shell\n",
    "sudo apt install python3-openstackclient\n",
    "sudo apt install python3-novaclient\n",
    "sudo apt install python3-keystoneclient\n",
    "```\n",
    "__NOTE:__ You need to setup variable values in the `start_instance.py` script.\\\n",
    "您需要在`start_instance.py`脚本中设置变量值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Once you setup the environment, run the following command.\n",
    "设置好环境后，运行以下命令。\n",
    "\n",
    "```shell\n",
    "cd model_serving/openstack-client/single_node_without_docker_client/\n",
    "python3 start_instance.py\n",
    "```\n",
    "\n",
    "Output:\n",
    "```shell\n",
    "user authorization completed.\n",
    "Creating instance ... \n",
    "waiting for 10 seconds.. \n",
    "Instance: prod_server_without_docker_2930 is in BUILD state, sleeping for 5 seconds more...\n",
    "Instance: prod_server_without_docker_2930 is in ACTIVEstate\n",
    "```\n",
    "\n",
    "The command will start a new server and initiate the contextualization process. It will take approximately 10 to 15 minutes. The progress can be seen on the cloud dashboard. Once the process finish, attach a floating IP to your production server and access the webpage from your client machine.\\\n",
    "该命令将启动一个新服务器并启动contextualization过程。大约需要10到15分钟。可以在云dashboard上看到进展。处理完成后，将一个浮动IP附加到生产服务器上，并从client机器访问该网页。\n",
    "\n",
    "Welcome page:\n",
    "* `http://<PRODUCTION-SERVER-IP>:5100`\n",
    "* http://130.238.28.163:5100\n",
    "\n",
    "Predictions page:\n",
    "* `http://<PRODUCTION-SERVER-IP>:5100/predictions`\n",
    "* http://130.238.28.163:5100/predictions\n",
    "\n",
    "***TERMINATE THE PRODUCTION SERVER VM STARTED FOR TASK-1!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Explain how the application works? Write a short paragraph about the framework.\n",
    "解释应用程序如何工作？写一段简短的框架。\n",
    "\n",
    "**Answer**\n",
    "\n",
    "In the client server, Cloud-Init configuration file `cloud-cfg.txt` and OpenStack python code `start_instance.py` will be used to initiate a new production server and contextualize it at run time. Production server hosts the complete application and provide a web interface to access the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are the drawbacks of the contextualization strategy adopted in the task-1? Write at least four drawbacks.\n",
    "在task-1中采用的上下文化策略的缺点是什么？至少写出四个缺点。\n",
    "\n",
    "* [A Practical Guide to Choosing between Docker Containers and VMs](https://www.weave.works/blog/a-practical-guide-to-choosing-between-docker-containers-and-vms)\n",
    "* [Are Containers Replacing Virtual Machines?](https://www.docker.com/blog/containers-replacing-virtual-machines/)\n",
    "* [Docker Containers vs. Virtual Machines](https://www.aquasec.com/cloud-native-academy/docker-container/docker-containers-vs-virtual-machines/)\n",
    "* [Docker vs. Virtual Machine: Differences You Need to Know](https://www.simplilearn.com/tutorials/docker-tutorial/docker-vs-virtual-machine)\n",
    "* [How is Docker different from a virtual machine?](https://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-virtual-machine)\n",
    "* [What’s the Diff: VMs vs Containers](https://www.backblaze.com/blog/vm-vs-containers/)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "* Heavyweight. Each VM runs not just a full copy of an operating system, but a virtual copy of all the hardware that the operating system needs to run, which quickly adds up to a lot of RAM and CPU cycles.\n",
    "\n",
    "* Resource consuming. Since VM uses a separate OS; it causes more resources to be used.\n",
    "\n",
    "* Slow provisioning. To deploy a single application, Virtual Machines need to start the entire OS, which would cause a full boot process\n",
    "\n",
    "* Lack of portability. While transferring files, VMs should have a copy of the OS and its dependencies because of which image size is increased and becomes a tedious process to share data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Currently, the contextualization process takes 10 to 15 minutes. How can we reduce the deployment time?\n",
    "目前，contextualization过程需要10到15分钟。我们如何减少部署时间?\n",
    "\n",
    "* [A Practical Guide to Choosing between Docker Containers and VMs](https://www.weave.works/blog/a-practical-guide-to-choosing-between-docker-containers-and-vms)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Docker containers typically start in a few seconds or less, whereas virtual machines can take minutes. Thus, workloads that need to start very quickly, or that involve spinning apps up and down constantly, may be a good fit for Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write half a page summary about the task and add screenshots if needed.\n",
    "写半页的任务总结，如果需要的话添加截图。\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Run command `python3 start_instance.py` to start a new server and initiate the contextualization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-2: Single Server Deployment with Docker Containers\n",
    "\n",
    "In this task, we will repeat the same deployment process but with Docker containers. This time we will create a flexible containerized deployment environment where each container has a defined role.\\\n",
    "在本任务中，我们将重复相同的部署过程，但使用的是Docker容器。这一次，我们将创建一个灵活的容器化部署环境，其中每个容器都有一个已定义的角色。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Go to `model_serving/single_server_with_docker/production_server/` directory on the client VM. \n",
    "\n",
    "The directory contains the code that will run on your production server.\\\n",
    "该目录包含将在production服务器上运行的代码。\n",
    "\n",
    "Following is the structure of the code:\n",
    "* Flask Application based frontend\n",
    "    * `app.py`\n",
    "    * `static`\n",
    "    * `templates`\n",
    "* Celery and RabbitMQ setup\n",
    "    * `run_task.py`\n",
    "    * `workerA.py`\n",
    "* Machine learning Model and Data\n",
    "    * `model.h5`\n",
    "    * `model.json`\n",
    "    * `pima-indians-diabetes.csv`\n",
    "* Docker files\n",
    "    * `Dockerfile`\n",
    "    * `docker-compose.yml`\n",
    "\n",
    "Open files and understand the application's structure.\\\n",
    "打开文件并理解应用程序的结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Go to the `model_serving/openstack-client/single_node_with_docker_client/` directory.\n",
    "\n",
    "The directory contains the code that we will use to contextualize the production server.\\\n",
    "该目录包含我们将用于将production服务器上下文化的代码。\n",
    "\n",
    "The code is based on the following two files:\n",
    "* Cloud-Init configuration file\n",
    "    * `cloud-cfg.txt`\n",
    "* OpenStack python code\n",
    "    * `start_instance.py`\n",
    "\n",
    "Open the files and understand the steps. You will need to update the `key_name` value in `start_instance.py` file with a previously created keypair.\\\n",
    "打开文件并理解其中的步骤。您需要使用先前创建的密钥对更新`start_instance.py`文件中的`key_name`值。\n",
    "```shell\n",
    "cd model_serving/openstack-client/single_node_with_docker_client/\n",
    "vim start_instance.py\n",
    "```\n",
    "\n",
    "__NOTE:__ You need to setup variable values in the `start_instance.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run the following command.\n",
    "\n",
    "```shell\n",
    "# Set the environment variables by sourcing the RC-file in the client VM.\n",
    "source DEII_L2_T1-openrc.sh\n",
    "cd model_serving/openstack-client/single_node_with_docker_client/\n",
    "python3 start_instance.py\n",
    "```\n",
    "\n",
    "Output:\n",
    "```shell\n",
    "user authorization completed.\n",
    "Creating instance ... \n",
    "waiting for 10 seconds.. \n",
    "Instance: prod_server_with_docker_4964 is in BUILD state, sleeping for 5 seconds more...\n",
    "Instance: prod_server_with_docker_4964 is in ACTIVE state\n",
    "```\n",
    "\n",
    "The command will start a new server and initiate the contextualization process. It will take approximately 10 to 15 minutes. The progress can be seen on the cloud dashboard. Once the process finish, attach a floating IP to your production server and access the webpage from your client machine.\\\n",
    "该命令将启动一个新服务器并启动contextualization过程。大约需要10到15分钟。可以在云仪表板上看到进展。处理完成后，将一个浮动IP附加到production服务器上，并从client机器访问该网页。\n",
    "\n",
    "Welcome page: \n",
    "* `http://<PRODUCTION-SERVER-IP>:5100`\n",
    "* http://130.238.28.163:5100\n",
    "\n",
    "Predictions page:\n",
    "* `http://<PRODUCTION-SERVER-IP>:5100/predictions`\n",
    "* http://130.238.28.163:5100/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. The next step is to test the horizontal scalability of the setup.\n",
    "下一步是测试设置的水平可伸缩性。\n",
    "\n",
    "* Login to the production server.\n",
    "```shell\n",
    "# ssh -i <PRIVATE KEY> ubuntu@<PRODUCTION-SERVER-IP>\n",
    "ssh -i /Users/lmf/PycharmProjects/MSc_DS/Important/key_DE.pem ubuntu@130.238.28.163\n",
    "```\n",
    "\n",
    "* Switch to the superuser mode.\n",
    "```shell\n",
    "sudo bash\n",
    "```\n",
    "\n",
    "* Check the cluster status:\n",
    "```shell\n",
    "cd /model_serving/single_server_with_docker/production_server\n",
    "docker-compose ps\n",
    "```\n",
    "Following three containers are running on the production server:\\\n",
    "以下三个容器正在生产服务器上运行：\n",
    "    * `production_server_rabbit_1` -> RabbitMQ server\n",
    "    * `production_server_web_1` -> Flask based web application\n",
    "    * `production_server_worker_1_1` -> Celery worker\n",
    "\n",
    "* Now we will add multiple workers in the cluster using docker commands.\\\n",
    "现在我们将使用docker命令在集群中添加多个worker。\n",
    "    * Currently, there is one worker available. We will add two more workers.\\\n",
    "    目前，只有一个worker可用。我们将再增加两名worker。\n",
    "    ```shell\n",
    "    docker-compose up --scale worker_1=3 -d\n",
    "    ```\n",
    "    Output:\n",
    "    ```shell\n",
    "    production_server_rabbit_1 is up-to-date\n",
    "    Starting production_server_worker_1_1 ... \n",
    "    Starting production_server_worker_1_1 ... done\n",
    "    Creating production_server_worker_1_2 ... done\n",
    "    Creating production_server_worker_1_3 ... done\n",
    "    ```\n",
    "    \n",
    "    * Check the cluster status.\\\n",
    "    检查集群状态。\n",
    "    ```shell\n",
    "    docker-compose ps\n",
    "    ```\n",
    "    Now we have 3 workers running in the system.\\\n",
    "    现在系统中有3个worker在运行。\n",
    "    \n",
    "    * Scale down the cluster.\\\n",
    "    缩小集群规模。\n",
    "    ```shell\n",
    "    docker-compose up --scale worker_1=1 -d\n",
    "    ```\n",
    "    Output:\n",
    "    ```shell\n",
    "    production_server_rabbit_1 is up-to-date\n",
    "    Stopping and removing production_server_worker_1_2 ... \n",
    "    Stopping and removing production_server_worker_1_2 ... done\n",
    "    Stopping and removing production_server_worker_1_3 ... done\n",
    "    ```\n",
    "\n",
    "***TERMINATE THE SERVER VM STARTED FOR TASK-2!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What problems Task-2 deployment strategy solves compared to the strategy adopted in Task-1?\n",
    "与Task-1相比，Task-2的部署策略解决了哪些问题?\n",
    "\n",
    "* [Why you should use Docker and containers](https://www.infoworld.com/article/3310941/why-you-should-use-docker-and-containers.html)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Docker enables more efficient use of system resources. Instances of containerized apps use far less memory than virtual machines, they start up and stop more quickly, and they can be packed far more densely on their host hardware.\\\n",
    "Docker可以更有效地利用系统资源。与虚拟机相比，容器化的应用实例使用的内存要少得多，它们启动和停止的速度更快，而且它们可以在主机硬件上更密集地打包。\n",
    "\n",
    "Docker enables application portability. Because Docker containers encapsulate everything an application needs to run (and only those things), they allow applications to be shuttled easily between environments.\\\n",
    "Docker支持应用程序的可移植性。因为Docker容器封装了应用程序需要运行的所有东西(而且只封装了那些东西)，所以它们允许应用程序轻松地在不同环境之间穿梭。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are the outstanding issues that the deployment strategy of Task-2 cannot not address?\n",
    "Task-2的部署策略不能解决的突出问题有哪些？\n",
    "\n",
    "##### 3. What are the possible solutions to address those outstanding issues?\n",
    "解决这些突出问题的可能解决办法是什么？\n",
    "\n",
    "* [When Not to Use Docker: Understanding the Limitations of Containers](https://www.channelfutures.com/open-source/when-not-to-use-docker-understanding-the-limitations-of-containers)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "* Security problem. Docker can improve security in some ways by isolating applications from the host system and from each other. Yet Docker also creates new security challenges — such as the difficulty of monitoring so many moving pieces within a dynamic, large-scale Docker environment. Running your processes inside the containers as a non-privileged user cannot guarantee security. It depends on the capabilities you add or remove. To mitigate the risks of Docker container breakout, you should not download ready-to-use containers from untrusted sources.\n",
    "\n",
    "* Lack of cross-platform compatibility. An application designed to run in a Docker container on Windows can’t run on Linux, and vice versa. In highly heterogeneous environments composed of both both Windows and Linux servers, this makes Docker less attractive. Sometimes, it is easier to set up a server if you have several static apps.\n",
    "\n",
    "* Data storage. By design, all Docker files are created inside a container and stored on a writable container layer. It may be difficult to retrieve the data out of the container if a different process needs it. Also, the writable layer of a container is connected to the host machine which the container is running on. If you need to move the data elsewhere, you cannot do it easily. More than that, all the data stored inside a container will be lost forever once the container shuts down. You have to think of ways to save your data somewhere else first. To keep data safe in Docker, you need to employ an additional tool – Docker Data Volumes. Yet, this solution is still quite clumsy and needs to be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. What is the difference between horizontal and vertical scalability? Is the strategy adopted in Task-2 follow horizontal or vertical scalability?\n",
    "水平可伸缩性和垂直可伸缩性之间的区别是什么？Task-2中采用的策略遵循的是水平可伸缩性还是垂直可伸缩性？\n",
    "\n",
    "* [Scaling Horizontally vs. Scaling Vertically](https://www.section.io/blog/scaling-horizontally-vs-vertically/)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Horizontal scaling means scaling by adding more machines to your pool of resources, whereas vertical scaling refers to scaling by adding more power (e.g. CPU, RAM) to an existing machine. The strategy adopted in Task-2 follow horizontal scalability, since it adds more workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write half a page summary about the task and add screenshots if needed.\n",
    "写半页的任务总结，如果需要的话添加截图。\n",
    "\n",
    "**Answer**\n",
    "\n",
    "The deployment process is similar to Task-1.\n",
    "\n",
    "Check the cluster status with the command `docker-compose ps`.\n",
    "\n",
    "Add 2 more workers in the cluster using docker commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Integration and Continuous Delivery (CI/CD)\n",
    "\n",
    "The next two tasks will cover scalable cluster deployments using Ansible playbooks and CI/CD environment using versioning system Git and an extension called Git Hooks.\\\n",
    "接下来的两个任务将涉及使用Ansible playbooks，和使用版本控制系统Git和名为Git Hooks的扩展的CI/CD环境的可扩展集群部署。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-3: Deployment of multiple servers using Ansible\n",
    "\n",
    "For this task we need a setup based on following three VMs:\n",
    "* Client VM: This machine will serve as an Ansible host name and initiate the configuration process.\\\n",
    "这台机器将作为一个Ansible host名，并启动配置过程。\n",
    "* Production Server: The machine will host the dockerised version of the application discussed in task-1.\\\n",
    "这台机器将托管task-1中讨论的应用程序的dockerised版本。\n",
    "* Development Server: The machine will host the development environment and push the new changes to the production server.\\\n",
    "这台机器将承载开发环境，并将新更改推送到production服务器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Steps to setup Ansible host and orchestration environment\n",
    "安装Ansible host和编配环境的步骤\n",
    "\n",
    "If you are not familiar with the Ansible, visit following URLs:\n",
    "* [Ansible is Simple IT Automation](https://www.ansible.com/)\n",
    "* [The Ansible Basics: Why Automation Matters Today in IT](https://www.ansible.com/blog/it-automation)\n",
    "* [OVERVIEW - How Ansible Works](https://www.ansible.com/overview/how-ansible-works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Login to the Client machine\n",
    "\n",
    "```shell\n",
    "# ssh -i <PRIVATE KEY> ubuntu@<PRODUCTION-SERVER-IP>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Go to `model_serving/ci_cd` directory. \n",
    "\n",
    "This directory contains the following two subdirectories\\\n",
    "此目录包含以下两个子目录\n",
    "\n",
    "`production_server`\n",
    "* Flask Application based frontend\n",
    "    * `app.py`\n",
    "    * `static`\n",
    "    * `templates`\n",
    "* Celery and RabbitMQ setup\n",
    "    * `run_task.py`\n",
    "    * `workerA.py`\n",
    "* Machine learning Model and Data\n",
    "    * `model.h5`\n",
    "    * `model.json`\n",
    "    * `pima-indians-diabetes.csv`\n",
    "\n",
    "`development_server`\n",
    "* Machine learning Model and Data\n",
    "    * `model.h5`\n",
    "    * `model.json`\n",
    "    * `pima-indians-diabetes.csv`\n",
    "    * `neural_net.py`\n",
    "\n",
    "Open files and understand the application's structure.\\\n",
    "打开文件并理解应用程序的结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Go to `model_serving/openstack-client/single_node_with_docker_ansible_client` directory. \n",
    "\n",
    "The files in the directory will be used to contextualize the production and deployment servers.\\\n",
    "目录中的文件将被用来使production服务器和deployment服务器contextualize。\n",
    "\n",
    "* CloudInit files\n",
    "    * `prod-cloud-cfg.txt`\n",
    "    * `dev-cloud-cfg.txt`\n",
    "* OpenStack code\n",
    "    * `start_instance.py`\n",
    "* Ansible files\n",
    "    * `setup_var.yml`\n",
    "    * `configuration.yml`\n",
    "\n",
    "The client code will start two VMs and by using Ansible orchestration environment. It will contextualize both of the VMs simultaneously.\\\n",
    "client代码将通过使用Ansible orchestration环境启动两个VM。它将同时contextualize这两个VM。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Install and configure Ansible on the client machine.\n",
    "在client机器上安装和配置Ansible。\n",
    "\n",
    "* First generate a cluster SSH key.\\\n",
    "首先生成一个集群SSH密钥。\n",
    "\n",
    "* Check the username you are login as\\\n",
    "检查您登录时使用的用户名\n",
    "```shell\n",
    "whoami\n",
    "```\n",
    "\n",
    "__Important:__ You need to be as ubuntu user. If you are root user switch back to ubuntu user.\\\n",
    "你必须是ubuntu用户。如果你是root用户切换回ubuntu用户。\n",
    "\n",
    "Create a directory\\\n",
    "创建一个目录\n",
    "```shell\n",
    "mkdir -p /home/ubuntu/cluster-keys\n",
    "ssh-keygen -t rsa\n",
    "```\n",
    "Set the file path `/home/ubuntu/cluster-keys/cluster-key`. Do not set the password, simply press Enter twice.\\\n",
    "设置文件路径为`/home/ubuntu/cluster-keys/cluster-key`。无需设置密码，只需按两次“Enter”即可。\n",
    "\n",
    "```shell\n",
    "Enter file in which to save the key (/home/ubuntu/.ssh/id_rsa): /home/ubuntu/cluster-keys/cluster-key\n",
    "Enter passphrase (empty for no passphrase): \n",
    "Enter same passphrase again: \n",
    "Your identification has been saved in /home/ubuntu/cluster-keys/cluster-key\n",
    "Your public key has been saved in /home/ubuntu/cluster-keys/cluster-key.pub\n",
    "The key fingerprint is:\n",
    "SHA256:KJOudYc7hBjrABiL6grt8j3p3Y3CCxDKdAJcJiX6ir4 ubuntu@mengfeiliang-l2\n",
    "The key's randomart image is:\n",
    "+---[RSA 3072]----+\n",
    "|ooo+             |\n",
    "|+.+              |\n",
    "|+=..             |\n",
    "|Bo+. . .         |\n",
    "|+.o++.. S        |\n",
    "|+ooo.o..         |\n",
    "|=o. ++o .        |\n",
    "|+o.+o+++ o       |\n",
    "|oE=.o.++o .      |\n",
    "+----[SHA256]-----+\n",
    "```\n",
    "\n",
    "* The step will generate cluster ssh keys at the following location:\\\n",
    "该步骤将在以下位置生成集群ssh密钥:\n",
    "    * Private key: `/home/ubuntu/cluster-keys/cluster-key`\n",
    "    * Public key: `/home/ubuntu/cluster-keys/cluster-key.pub`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Next, we will start the Production and Development servers.\n",
    "接下来，我们将启动Production和Development服务器。\n",
    "\n",
    "* Go to the `model_serving/openstack-client/single_node_with_docker_ansible_client`, open `prod-cloud-cfg.txt` delete the old key from the section `ssh_authorized_keys:` and copy the complete contents of `/home/ubuntu/cluster-keys/cluster-key.pub` in the `prod-cloud-cfg.txt` file.\\\n",
    "进入`model_serving/openstack-client/single_node_with_docker_ansible_client`，打开`prod-cloud-cfg.txt`从`ssh_authorized_keys:`小节中删除旧的密钥，并复制`/home/ubuntu/cluster-keys/cluster-key.pub`的完整内容到`prod-cloud-cfg.txt`文件中。\n",
    "```shell\n",
    "vim /home/ubuntu/cluster-keys/cluster-key.pub\n",
    "```\n",
    "client服务器上的集群公钥：\n",
    "```shell\n",
    "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC9jz5EfAQ8rgj/gNZpy0DU+LB4d6v/QUbb4uni9r+J190DW401PhvF2zQPzLnPfbSJSv+S/Qf9oL/vNwigOBYrV9Bpr9JFfNCbdbZx+nm7hKVe1Hjmk82o4gMtvmvmjudWIUmRVodXAyWkBzTevAKK6QJUndz11Ptjlp3Cgr4s9Dr5hbTesQFKF886QgG0i7Kr+HB13mqxFq936hxRgj+MVjzA9hB0aLjsD1GklDBLBV1bCZAR+v1mucSASkGcWpvGtsnUPZMqVtccOiBCChWELN+5VyNbzt/J9AAUW4aoOAqKhWplETicjR8ST9efNkfNaMhyGrLRNetZCSvg59+l7DEt0d+Vf/45hYeFQUrY7Se5ZylQB8yVHl4xfX77sxGiMIU8FcVBtLLIJFYI2NTJgmtRi6BVoLMGC1Q9IyTPbbsahk+ZgUHrFZwLbGtBKevQysIh+M6l7zDaJ2aedWRMYBMu/WRISM2oGDHn5GyfUqOe97tejBaw5wSbXWXVSI8= ubuntu@mengfeiliang-l2\n",
    "```\n",
    "```shell\n",
    "cd model_serving/openstack-client/single_node_with_docker_ansible_client\n",
    "vim prod-cloud-cfg.txt\n",
    "```\n",
    "\n",
    "* Repeat same step 3 with the `dev-cloud-cfg.txt`. Delete the old key from the section `ssh_authorized_keys:` and copy the complete contents of `/home/ubuntu/clusterkeys/cluster-key.pub` in the `dev-cloud-cfg.txt` file.\\\n",
    "使用`dev-cloud-cfg.txt`重复相同的步骤3。删除`ssh_authorized_keys:`小节中的旧键，并复制`/home/ubuntu/clusterkeys/cluster-key.pub`的完整内容到在`dev-cloud-cfg.txt`文件中。\n",
    "```shell\n",
    "cd model_serving/openstack-client/single_node_with_docker_ansible_client\n",
    "vim dev-cloud-cfg.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Run the `start_instances.py` code.\n",
    "\n",
    "```shell\n",
    "source DEII_L2_T1-openrc.sh\n",
    "cd model_serving/openstack-client/single_node_with_docker_ansible_client\n",
    "vim start_instances.py\n",
    "python3 start_instances.py\n",
    "```\n",
    "\n",
    "The output will give you the internal IPs of the VMs.\n",
    "```shell\n",
    "user authorization completed.\n",
    "Creating instances ... \n",
    "waiting for 10 seconds.. \n",
    "Instance: prod_server_with_docker_2638 is in BUILD state, sleeping for 5 seconds more...\n",
    "Instance: dev_server_2638 is in BUILD state, sleeping for 5 seconds more...\n",
    "Instance: prod_server_with_docker_2638 is in ACTIVE state ip address: 192.168.2.198\n",
    "Instance: dev_server_2638 is in ACTIVE state ip address: 192.168.2.80\n",
    "```\n",
    "\n",
    "Now we have two VM running with the internal IP addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Install Ansible packages on the client machine.\n",
    "在client机器上安装Ansible包\n",
    "\n",
    "```shell\n",
    "sudo bash\n",
    "apt update; apt upgrade\n",
    "apt-add-repository ppa:ansible/ansible\n",
    "apt update\n",
    "apt install ansible\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Next step is to enter these IP addresses in the Ansible hosts file.\n",
    "下一步是在Ansible hosts文件中输入这些IP地址。\n",
    "\n",
    "Open the Ansible inventory file and add the IP addresses in that file.\\\n",
    "打开Ansible目录文件，并在该文件中添加IP地址。\n",
    "\n",
    "For this step you need to swtich to root user.\\\n",
    "对于这个步骤，您需要切换到root用户。\n",
    "```shell\n",
    "sudo bash\n",
    "nano /etc/ansible/hosts\n",
    "```\n",
    "\n",
    "File contents:\\\n",
    "文件内容：\n",
    "```shell\n",
    "[servers]\n",
    "# prodserver ansible_host=<production server IP address>\n",
    "# devserver ansible_host=<development server IP address>\n",
    "prodserver ansible_host=192.168.2.198\n",
    "devserver ansible_host=192.168.2.80\n",
    "\n",
    "[all:vars]\n",
    "ansible_python_interpreter=/usr/bin/python3\n",
    "\n",
    "[prod_server]\n",
    "prodserver ansible_connection=ssh ansible_user=appuser\n",
    "\n",
    "[dev_server]\n",
    "devserver ansible_connection=ssh ansible_user=appuser\n",
    "```\n",
    "\n",
    "If you need to learn more about Ansible, here are some useful links:\\\n",
    "如果你想了解更多关于Ansible的信息，这里有一些有用的链接:\\\n",
    "Easy installation instructions [How to Install and Configure Ansible on Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-ansible-on-ubuntu-18-04)\n",
    "\n",
    "* Just to confirm the access permission are correctly set, access production and development server from the client VM.\\\n",
    "为了确认访问权限设置正确，请从client VM访问production和development服务器。\n",
    "\n",
    "First switch back to user ubuntu\\\n",
    "首先切换回用户ubuntu\n",
    "```shell\n",
    "# ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@<PRODUCTION-SERVER-IP>\n",
    "ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@192.168.2.198\n",
    "```\n",
    "If the login is successful, exit from the production server. Repeat the step with development server.\\\n",
    "如果登录成功，请退出production服务器。在development服务器上重复此步骤。\n",
    "```shell\n",
    "# ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@<DEVELOPMENT-SERVER-IP>\n",
    "ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@192.168.2.80\n",
    "```\n",
    "If the login is successful, exit from the development server.\\\n",
    "如果登录成功，请退出开发服务器。\n",
    "\n",
    "For this step, switch to ubuntu user on the client VM.\\\n",
    "该步骤需要在client虚拟机上切换为ubuntu用户。\n",
    "\n",
    "Now we will run the Ansible script available in the `model_serving/openstack-client/single_node_with_docker_ansible_client` directory.\\\n",
    "现在我们将运行`model_serving/openstack-client/single_node_with_docker_ansible_client`目录中的Ansible脚本。\n",
    "```shell\n",
    "export ANSIBLE_HOST_KEY_CHECKING=False\n",
    "ansible-playbook configuration.yml --private-key=/home/ubuntu/cluster-keys/cluster-key\n",
    "```\n",
    "\n",
    "The process will take 10 to 15 minutes to complete.\\\n",
    "这个过程需要10到15分钟才能完成。\n",
    "\n",
    "Attach floating IP address to the production server and access the same predictions webpage as we did in previous tasks.\\\n",
    "将浮动IP地址附加到production服务器上，并访问我们在前面的任务中所做的相同的预测网页。\n",
    "\n",
    "Welcome page: \n",
    "* `http://<PRODUCTION-SERVER-IP>:5100`\n",
    "* http://130.238.28.163:5100\n",
    "\n",
    "Predictions page:\n",
    "* `http://<PRODUCTION-SERVER-IP>:5100/predictions`\n",
    "* http://130.238.28.163:5100/predictions\n",
    "\n",
    "***Important: Task-4 is the continuation of Task-3. Do NOT terminate your instances setup in Task-3.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What is the difference between CloudInit and Ansible?\n",
    "CloudInit和Ansible的区别是什么?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Cloud-Init is the industry standard multi-distribution method for cross-platform cloud instance initialization. It is supported across all major public cloud providers, provisioning systems for private cloud infrastructure, and bare-metal installations.\\\n",
    "Cloud-Init是用于跨平台云实例初始化的行业标准多分发方法。所有主要的公共云提供商、私有云基础设施的供应系统和裸金属安装都支持它。\n",
    "\n",
    "Ansible is a radically simple IT automation engine that automates cloud provisioning, configuration management, application deployment, intra-service orchestration, and many other IT needs.\\\n",
    "Ansible是一个非常简单的IT自动化引擎，它可以自动化云供应、配置管理、应用程序部署、服务内部编排和许多其他IT需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Explain the configurations available in `dev-cloud-cfg.txt` and `prod-cloud-cfg.txt` files.\n",
    "解释`dev-cloud-cfg.txt`和`prod-cloud-cfg.txt`文件中可用的配置。\n",
    "\n",
    "* [How To Use Cloud-Config For Your Initial Server Setup](https://www.digitalocean.com/community/tutorials/how-to-use-cloud-config-for-your-initial-server-setup)\n",
    "* [An Introduction to Cloud-Config Scripting](https://www.digitalocean.com/community/tutorials/an-introduction-to-cloud-config-scripting)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "To create a new user, we use the `users` directive. \n",
    "\n",
    "`sudo: ALL=(ALL) NOPASSWD:ALL` configures password-less `sudo` access.\n",
    "\n",
    "`home` directive is used to set the local path you want to use.\n",
    "\n",
    "Default `/bin/sh` shell is a very basic environment, so we want to manually specify a `bash` shell environment for our new user, which can be accomplished with the `shell` directive.\n",
    "\n",
    "In order to log into this new account without a password, we will need to provide one or more of our SSH public keys, which can be accomplished with the `ssh-authorized-keys` directive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. What problem we have solved by using Ansible?\n",
    "我们使用Ansible解决了什么问题?\n",
    "\n",
    "* [Ansible | Ansible Use Cases](https://www.ansible.com/use-cases)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "* Orchestration. Today’s IT brings complex deployments and complex challenges. Ansible can make it easier to orchestrate the complex tasks such as dealing with clustered applications, multiple datacenters, public, private and hybrid clouds and applications with complex dependencies.\n",
    "\n",
    "* Continuous delivery. Ansible Playbooks keep the applications properly deployed (and managed) throughout their entire lifecycle.\n",
    "\n",
    "* Configuration management. Ansible centralizes configuration file management and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-4: CI/CD using Git HOOKS\n",
    "\n",
    "In this task, we will build a reliable execution pipeline using Git Hooks. The pipeline will allow continuous integration and delivery of new machine learning models in a production environment.\\\n",
    "在这个任务中，我们将使用Git Hooks构建一个可靠的执行管道。该流水线将允许在生产环境中持续集成和交付新的机器学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Enable SSH key based communication between production and development servers\n",
    "在production服务器和development服务器之间启用基于SSH密钥的通信\n",
    "\n",
    "* Login to the development server\\\n",
    "登录到development服务器\n",
    "```shell\n",
    "ssh -i /Users/lmf/PycharmProjects/MSc_DS/Important/key_DE.pem ubuntu@130.238.29.126\n",
    "# ssh -i cluster-key appuser@<DEVELOPMENT-SERVER-IP>\n",
    "ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@192.168.2.80\n",
    "```\n",
    "\n",
    "* Generate SSH key\\\n",
    "生成SSH密钥\n",
    "```shell\n",
    "ssh-keygen\n",
    "```\n",
    "Output:\n",
    "\n",
    "```shell\n",
    "Generating public/private rsa key pair.\n",
    "Enter file in which to save the key (/home/appuser/.ssh/id_rsa): \n",
    "Enter passphrase (empty for no passphrase): \n",
    "Enter same passphrase again: \n",
    "Your identification has been saved in /home/appuser/.ssh/id_rsa\n",
    "Your public key has been saved in /home/appuser/.ssh/id_rsa.pub\n",
    "The key fingerprint is:\n",
    "SHA256:CGj5iz+y94LmoqoB5I0jXUPWD79EhVAJumDV3bo1TtY appuser@devserver\n",
    "The key's randomart image is:\n",
    "+---[RSA 3072]----+\n",
    "|    +oo=.=.      |\n",
    "|   * .+ = .      |\n",
    "| .* =  = . .     |\n",
    "|o+o+ + .= = E    |\n",
    "|o+..o ..SB .     |\n",
    "|o .. .  o .      |\n",
    "|. ...            |\n",
    "|..+.+            |\n",
    "|B+o+.+.          |\n",
    "+----[SHA256]-----+\n",
    "```\n",
    "\n",
    "__Important:__ Do not change the default `/home/appuser/.ssh/id_rsa` path of the file.\\\n",
    "不要更改文件的默认`/home/appuser/.ssh/id_rsa`路径。\n",
    "\n",
    "Do not set the password, simply press Enter twice.\\\n",
    "无需设置密码，只需按两次“Enter”即可。\n",
    "\n",
    "__NOTE:__ This step will create two files, private key `/home/appuser/.ssh/id_rsa` and public key `/home/appuser/.ssh/id_rsa.pub`.\\\n",
    "这一步将创建两个文件，私钥`/home/appuser/.ssh/id_rsa`和公钥`/home/appuser/.ssh/id_rsa.pub`。\n",
    "\n",
    "* Copy the contents of public key file `/home/appuser/.ssh/id_rsa.pub` from the development server.\\\n",
    "从development服务器拷贝公钥文件`/home/appuser/.ssh/id_rsa.pub`的内容。\n",
    "```shell\n",
    "vim /home/appuser/.ssh/id_rsa.pub\n",
    "```\n",
    "Public key of the development server:\\\n",
    "development服务器的公钥：\n",
    "```shell\n",
    "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDtvf8h2aotsTeNDTo/WVfo/XuuUhR+NpsOQI8JJ0+Xnvgz9eDNHxmHC1PJvA3e2j49Z3d9m4edMCI9fxvo8SLGh0nsWU2h5iwDQEn5ORAk7OwbziI2fu4wMCHa3zrAlpVinaqi0Y7ddghlCFz6a6JPYPUrTNjUDIOOwYndcJNOxEnzE+EX2Vlu1YoT3P/IWSEemW+Jj4qpk5Svjg3ETX6TvICU2WuOq4VI5X4eKNdgVzADiwJ2eWAWLZodWGlqPh4EUNx3hh3Ybt+Sdb0O14NtEwcao5Vg1VxX1n1w5WEXIfdcNobyvsqYPbZijUBQxe/HCERQXarsnx5B8/RizBqW1G6BTodWHUoaz6uzOEZrN3/qfOPzbDVvINphI83OZq/rCMUy5RqsvQXVOG1f3zl5JOL2AFu8BXorVELG9MG11ICEoigf/sMJddLEdBNIew7Io8ICS6bgaoh2YQleP+BYUDVwAHAtNaMmlIfBSVkQUaS7UmnW7Q0oJkUvjsFqwps= appuser@devserver\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Login to production server\n",
    "\n",
    "```shell\n",
    "# ssh -i cluster-key appuser@<PRODUCTION-SERVER-IP>\n",
    "ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@192.168.2.198\n",
    "```\n",
    "\n",
    "* Open file `/home/appuser/.ssh/authorized_keys` and paste the contents of the public key file in the `authorized_keys` file.\\\n",
    "打开文件`/home/appuser/.ssh/authorized_keys`，并将公钥文件的内容粘贴到`authorized_keys`文件中。\n",
    "```shell\n",
    "nano /home/appuser/.ssh/authorized_keys\n",
    "vim .ssh/authorized_keys\n",
    "```\n",
    "    **Note:** Do not delete the public key of client machine, otherwise you will fail to log in production server from client server.\n",
    "\n",
    "* Create a directory (it will be jump directory)\\\n",
    "创建一个目录(它将是跳转目录)\n",
    "```shell\n",
    "pwd\n",
    "```\n",
    "Output:\n",
    "```shell\n",
    "/home/appuser/\n",
    "```\n",
    "```shell\n",
    "mkdir my_project\n",
    "cd my_project\n",
    "```\n",
    "\n",
    "* Here is the path to your jump directory. Double check that user appuser is the owner of `my_project` directory.\\\n",
    "下面是跳转目录的路径。仔细检查用户appuser是`my_project`目录的所有者。\n",
    "```shell\n",
    "pwd\n",
    "```\n",
    "Output:\n",
    "```shell\n",
    "/home/appuser/my_project\n",
    "```\n",
    "Create git empty directory\\\n",
    "创建git空目录\n",
    "```shell\n",
    "git init --bare\n",
    "```\n",
    "```shell\n",
    "Initialized empty Git repository in /home/appuser/my_project/\n",
    "```\n",
    "The command will initialize empty Git repository in `/home/appuser/my_project/`.\\\n",
    "该命令将在`/home/appuser/my_project/`中初始化一个空Git存储库。\n",
    "\n",
    "* Create a git hook post-receive\\\n",
    "创建一个git hook post-receive\n",
    "```shell\n",
    "nano hooks/post-receive\n",
    "vim hooks/post-receive\n",
    "```\n",
    "File contents:\n",
    "```shell\n",
    "#!/bin/bash\n",
    "while read oldrev newrev ref\n",
    "do\n",
    "    if [[ $ref =~ .*/master$ ]];\n",
    "    then\n",
    "        echo \"Master ref received. Deploying master branch to production...\"\n",
    "        sudo git --work-tree=/model_serving/ci_cd/production_server --git-dir=/home/appuser/my_project checkout -f\n",
    "    else\n",
    "        echo \"Ref $ref successfully received. Doing nothing: only the master branch may be deployed on this server.\"\n",
    "    fi\n",
    "done\n",
    "```\n",
    "\n",
    "* Change permissions\\\n",
    "改变权限\n",
    "```shell\n",
    "# nano chmod +x hooks/post-receive\n",
    "chmod +x hooks/post-receive\n",
    "```\n",
    "    * `chmod +x + <file_name>`: 给执行权限，字体变为粗体绿色。\n",
    "    * `chmod -x + <file_name>`: 去除执行权限，字体变为常规黑色。\n",
    "\n",
    "* Exit Production Server\\\n",
    "退出Production服务器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Login to the Development Server\n",
    "\n",
    "```shell\n",
    "# ssh -i cluster-key appuser@<DEVELOPMENT-SERVER-IP>\n",
    "ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@192.168.2.80\n",
    "```\n",
    "\n",
    "* Create a directory\n",
    "```shell\n",
    "pwd\n",
    "```\n",
    "Output:\n",
    "```\n",
    "/home/appuser/\n",
    "```\n",
    "```shell\n",
    "mkdir my_project\n",
    "cd my_project\n",
    "```\n",
    "\n",
    "* This is your development directory. Double check that user appuser is the owner of `my_project` directory.\\\n",
    "这是您的development目录。仔细检查用户appuser是`my_project`目录的所有者。\n",
    "```shell\n",
    "pwd\n",
    "```\n",
    "Output:\n",
    "```shell\n",
    "/home/appuser/my_project\n",
    "```\n",
    "\n",
    "* Create empty git repository\\\n",
    "创建空的git库\n",
    "```shell\n",
    "git init\n",
    "```\n",
    "Output:\n",
    "```shell\n",
    "Initialized empty Git repository in /home/appuser/my_project/.git/\n",
    "```\n",
    "\n",
    "* Add files `model.h5` and `model.json` in `/home/appuser/my_project/` directory. The files are available in `model_serving/ci_cd/development_server/` directory.\\\n",
    "添加文件`model.h5`和`model.json`到`/home/appuser/my_project/`目录。这些文件可以在`model_serving/ci_cd/development_server/`目录中找到。\n",
    "```shell\n",
    "# Add files `model.h5` and `model.json`\n",
    "scp -i /home/ubuntu/cluster-keys/cluster-key -r model_serving/ci_cd/development_server/model* appuser@192.168.2.80:/home/appuser/my_project\n",
    "```\n",
    "\n",
    "* Go to the `/home/appuser/my_project` directory\\\n",
    "进入`/home/appuser/my_project`目录\n",
    "```shell\n",
    "cd my_project\n",
    "```\n",
    "\n",
    "* Add files for the commit\n",
    "```shell\n",
    "git add .\n",
    "```\n",
    "\n",
    "* Commit files\n",
    "```shell\n",
    "git commit -m \"new model\"\n",
    "```\n",
    "```shell\n",
    "# Please tell me who you are.\n",
    "git config --global user.email \"mengfei.liang.2445@student.uu.se\"\n",
    "git config --global user.name \"MengFeiLiang\"\n",
    "```\n",
    "\n",
    "* Connect development server's git to production server's git.\\\n",
    "连接development服务器的git到production服务器的git。\n",
    "```shell\n",
    "# git remote add production appuser@<PRODUCTIONS-SERVER-IP>:/home/appuser/my_project\n",
    "git remote add production appuser@192.168.2.198:/home/appuser/my_project\n",
    "```\n",
    "\n",
    "* Push your commits to the production server\\\n",
    "将提交推到生产服务器\n",
    "```shell\n",
    "git push production master\n",
    "```\n",
    "\n",
    "In case you want to learn more about Git Hooks, visit the following link: [How To Use Git Hooks To Automate Development and Deployment Tasks](https://www.digitalocean.com/community/tutorials/how-to-use-git-hooks-to-automate-development-and-deployment-tasks)\\\n",
    "如果你想了解更多关于Git hook的知识，请访问以下链接：[如何使用Git hook自动化开发和部署任务](https://www.digitalocean.com/community/tutorials/how-to-use-git-hooks-to-automate-development-and-deployment-tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Go to `/model_serving/ci_cd/development_server/` directory. \n",
    "\n",
    "The directory contains the `neural_net.py` python script. The script will train a model and generate new model files `model.h5` and `model.json`. Open the training script `neural_net.py`, make changes in the model, install dependencies (`numpy` will be required) and run the script, move them in the git repository, commit changes and then push new model files in the running production pipeline.\\\n",
    "该目录包含`neural_net.py` python脚本。该脚本将训练一个模型并生成新的模型文件的`model.h5`和`model.json`。打开训练脚本`neural_net.py`，对模型进行更改，安装依赖项（需要`numpy`）并运行脚本，将它们移动到git存储库中，提交更改，然后在运行的生产管道中推入新的模型文件。\n",
    "\n",
    "Install dependencies:\n",
    "```shell\n",
    "ssh -i /Users/lmf/PycharmProjects/MSc_DS/Important/key_DE.pem ubuntu@130.238.29.126\n",
    "python3 --version\n",
    "sudo apt install python3-pip\n",
    "pip3 --version\n",
    "pip3 install numpy\n",
    "pip3 install keras\n",
    "pip3 install tensorflow\n",
    "```\n",
    "\n",
    "Error:\n",
    "```shell\n",
    "Waiting for cache lock: Could not get lock /var/lib/dpkg\n",
    "```\n",
    "在这个时候，主要是因为apt还在运行，此时的解决方案如下：找到并且杀掉所有的`apt-get`和`apt`进程\n",
    "```shell\n",
    "ps -A | grep apt\n",
    "sudo kill -9 <进程ID>\n",
    "```\n",
    "\n",
    "* Run the script\\\n",
    "运行脚本\n",
    "```shell\n",
    "cd model_serving/ci_cd/development_server\n",
    "python3 neural_net.py\n",
    "```\n",
    "Output:\n",
    "```python\n",
    "Accuracy: 76.86\n",
    "Saved model to disk\n",
    "Loaded model from disk\n",
    "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 0 (expected 1)\n",
    "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
    "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 0 (expected 1)\n",
    "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
    "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 0 (expected 1)\n",
    "```\n",
    "\n",
    "* Copy model files (`model.h5` and `model.json`) from the development directory `model_serving/ci_cd/development_server` to the git repository `/home/appuser/project` on the development server.\\\n",
    "从development目录`model_serving/ci_cd/development_server/`复制模型文件（`model.h5`和`model.json`）到development服务器的git仓库`/home/appuser/project`里。\n",
    "```shell\n",
    "# cp model_serving/ci_cd/development_server/model* /home/appuser/my_project/.\n",
    "scp -i /home/ubuntu/cluster-keys/cluster-key -r model_serving/ci_cd/development_server/model* appuser@192.168.2.80:/home/appuser/my_project/.\n",
    "```\n",
    "\n",
    "* Add to the git repository.\n",
    "```shell\n",
    "ssh -i /home/ubuntu/cluster-keys/cluster-key appuser@192.168.2.80\n",
    "cd my_project\n",
    "git add .\n",
    "```\n",
    "\n",
    "* Finally, commit and push the new model files.\\\n",
    "最后，提交并推入新的模型文件。\n",
    "```shell\n",
    "git commit -m \"new model\"\n",
    "git push production master\n",
    "```\n",
    "Output:\n",
    "```shell\n",
    "Enumerating objects: 5, done.\n",
    "Counting objects: 100% (5/5), done.\n",
    "Delta compression using up to 2 threads\n",
    "Compressing objects: 100% (3/3), done.\n",
    "Writing objects: 100% (3/3), 1.22 KiB | 1.22 MiB/s, done.\n",
    "Total 3 (delta 1), reused 0 (delta 0)\n",
    "remote: Master ref received. Deploying master branch to production...\n",
    "To 192.168.2.198:/home/appuser/my_project\n",
    "   e2567cb..6be510c  master -> master\n",
    "```\n",
    "\n",
    "* Access the URL `http://<PRODUCTION-SERVER-IP>:5100/predictions` and you will see the changes in predictions.\n",
    "    * http://130.238.28.163:5100/predictions\n",
    "\n",
    "* Improve the model by changing parameters or network architecture in the `neural_net.py` file and repeat the step-3 to push the new model to the production pipeline.\\\n",
    "通过更改`neural_net.py`文件中的参数或网络架构来改进模型，并重复步骤3将新模型推到生产管道中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What are git hooks? Explain the `post-receive` script available in this task.\n",
    "什么是git hooks？解释此任务中的`post-receive`脚本。\n",
    "\n",
    "* [Git Hooks | Atlassian Git Tutorial](https://www.atlassian.com/git/tutorials/git-hooks)\n",
    "* [8.3 Customizing Git - Git Hooks](https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Git hooks are scripts that run automatically every time a particular event occurs in a Git repository. They let you customize Git's internal behavior and trigger customizable actions at key points in the development life cycle.\\\n",
    "Git hooks是每当Git存储库中发生特定事件时自动运行的脚本。它们允许您定制Git的内部行为，并在开发生命周期的关键时刻触发可定制的操作。\n",
    "\n",
    "The `post-receive` hook runs after the entire process is completed and can be used to update other services or notify users.\\\n",
    "`post-receive` hook 在整个进程完成后运行，可以用来更新其他服务或通知用户。\n",
    "\n",
    "For each ref being pushed, the three pieces of info (`old rev`, `new rev`, `ref`) will be fed to the script, separated by white space, as standard input. We can read this with a `while` loop to surround the `git` command.\n",
    "So now, we will have three variables set based on what is being pushed. For a master branch push, the `ref` object will contain something that looks like `refs/heads/master`. We can check to see if the ref the server is receiving has this format by using an `if` construct.\n",
    "We should add an `else` block to notify the user when a non-master branch was successfully received, even though the action won’t trigger a deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. We have created an empty git repository on the production server. Why we need that directory?\n",
    "我们已经在production服务器上创建了一个空的git存储库。为什么我们需要那个目录?\n",
    "\n",
    "* [How To Use Git Hooks To Automate Development and Deployment Tasks](https://www.digitalocean.com/community/tutorials/how-to-use-git-hooks-to-automate-development-and-deployment-tasks)\n",
    "* [Using Git for Deployment - UserFrosting Documentation](https://learn.userfrosting.com/going-live/vps-production-environment/git-for-deployment)\n",
    "\n",
    "**Answer**\n",
    "\n",
    "A bare repository does not have a working directory and is better for servers that you will not be working with much directly.\\\n",
    "裸存储库没有工作目录，对于您不会直接使用的服务器来说更好。\n",
    "\n",
    "The reason we use a bare repository is because it separates the location of the repository (the files managed by git that live in the .git directory), and the working tree (the files you normally work with and from which you commit to the repository).\\\n",
    "我们使用裸存储库的原因是它分离了存储库的位置(位于.git目录中的git管理的文件)和工作树(您通常使用和向存储库提交的文件)。\n",
    "\n",
    "If we used a non-bare repository, we wouldn't be able to \"push to production\" because git does not allow you to push to a checked-out branch. Since the checked-out branch would be the actual set of files that the webserver is running your application on, it would make it impossible to change these files when we do git push.\\\n",
    "如果我们使用一个非裸存储库，我们将不能“推送到生产”，因为git不允许你推送到一个签出的分支。因为签出分支将是运行你的应用程序的web服务器上的实际文件集，所以当我们做git push时，它将不可能改变这些文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write the names of four different git hooks and explain their functionalities.\n",
    "写出四个不同git hooks的名称，并解释它们的功能。\n",
    "\n",
    "* [Git Hooks | Atlassian Git Tutorial](https://www.atlassian.com/git/tutorials/git-hooks)\n",
    "\n",
    "**Hints:** Read the link available in the task or access sample scripts available in the hooks directory.\\\n",
    "读取任务中可用的链接，或者访问hook目录中可用的示例脚本。\n",
    "\n",
    "**Answer**\n",
    "\n",
    "* `Pre-Commit`\\\n",
    "The `pre-commit` script is executed every time you run `git commit` before Git asks the developer for a commit message or generates a commit object. This hook is used to inspect the snapshot that is about to be committed.\n",
    "\n",
    "* `Prepare Commit Message`\\\n",
    "The `prepare-commit-msg` hook is called after the `pre-commit` hook to populate the text editor with a commit message. This is a good place to alter the automatically generated commit messages for squashed or merged commits.\n",
    "\n",
    "* `Commit Message`\\\n",
    "The `commit-msg` hook is much like the `prepare-commit-msg` hook, but it’s called after the user enters a commit message. This is an appropriate place to warn developers that their message doesn’t adhere to your team’s standards.\n",
    "\n",
    "* `Post-Commit`\\\n",
    "The `post-commit` hook is called immediately after the `commit-msg` hook. It can not change the outcome of the `git commit` operation, so it’s used primarily for notification purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. How deployment of multiple servers (in task 3) can be achieved with Kubernetes? Draw a diagram of the deployment highlighting the nodes, services, configuration map and secret.\n",
    "如何使用Kubernetes实现多台服务器（任务3中）的部署？绘制一个突出显示节点、服务、配置映射和秘密的部署图。\n",
    "\n",
    "How deployment of multiple servers can be achieved with Kubernetes? nodes, services, configuration map and secret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write half a page summary about the task and add screenshots if needed.\n",
    "写半页的任务总结，如果需要的话添加截图。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "337px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
