{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW OF RAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Ray\n",
    "\n",
    "#### Official Releases\n",
    "\n",
    "You can install the latest official version of Ray as follows. Official releases are produced according to the release process doc.\n",
    "```bash\n",
    "# Install pip\n",
    "sudo apt update\n",
    "sudo apt install python3-pip\n",
    "# Install ray\n",
    "pip3 install -U ray\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAY CLUSTERS/AUTOSCALER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Cluster Quick Start\n",
    "[Ray Cluster Quick Start](https://docs.ray.io/en/master/cluster/quickstart.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install some Python dependencies\n",
    "\n",
    "Before we start, you will need to install some Python dependencies as follows:\n",
    "```bash\n",
    "pip3 install -U 'ray[default]'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a (basic) Python application\n",
    "\n",
    "We will write a simple Python application that tracks the IP addresses of the machines that its tasks are executed on:\\\n",
    "我们将编写一个简单的Python应用程序，跟踪执行其任务的机器的IP地址:\n",
    "```python\n",
    "from collections import Counter\n",
    "import socket\n",
    "import time\n",
    "\n",
    "import ray\n",
    "\n",
    "ray.init()\n",
    "\n",
    "print('''This cluster consists of\n",
    "    {} nodes in total\n",
    "    {} CPU resources in total\n",
    "'''.format(len(ray.nodes()), ray.cluster_resources()['CPU']))\n",
    "\n",
    "@ray.remote\n",
    "def f():\n",
    "    time.sleep(0.001)\n",
    "    # Return IP address.\n",
    "    return socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "object_ids = [f.remote() for _ in range(10000)]\n",
    "ip_addresses = ray.get(object_ids)\n",
    "\n",
    "print('Tasks executed')\n",
    "for ip_address, num_tasks in Counter(ip_addresses).items():\n",
    "    print('    {} tasks on {}'.format(num_tasks, ip_address))\n",
    "```\n",
    "\n",
    "Save this application as `script.py`:\n",
    "```bash\n",
    "vim script.py\n",
    "```\n",
    "\n",
    "Execute it by running the command:\n",
    "```bash\n",
    "python3 script.py\n",
    "```\n",
    "\n",
    "Should now output something like:\n",
    "```bash\n",
    "This cluster consists of\n",
    "    1 nodes in total\n",
    "    4.0 CPU resources in total\n",
    "\n",
    "Tasks executed\n",
    "    10000 tasks on 127.0.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch a cluster\n",
    "\n",
    "After defining our configuration, we will use the Ray Cluster Launcher to start a cluster on the cloud, creating a designated “head node” and worker nodes. To start the Ray cluster, we will use the Ray CLI. Run the following command:\\\n",
    "在定义了我们的配置之后，我们将使用Ray Cluster Launcher在云上启动一个集群，创建一个指定的“头节点”和工作节点。为了启动Ray集群，我们将使用Ray CLI。执行如下命令:\n",
    "```bash\n",
    "ray up -y tune-default.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the application in the cloud\n",
    "\n",
    "We are now ready to execute the application in across multiple machines on our Ray cloud cluster. First, we need to edit the initialization command `ray.init()` in `script.py`.\\\n",
    "我们现在可以在Ray云集群的多台机器上执行应用程序了。首先，我们需要编辑`script.py`中的初始化命令`ray.init()`。\n",
    "```bash\n",
    "vim script.py\n",
    "```\n",
    "Change it to\\\n",
    "将其更改为\n",
    "```python\n",
    "ray.init(address='auto')\n",
    "# Pass `include_webui=True` to access the dashboard\n",
    "ray.init(address='auto', include_webui=True)\n",
    "```\n",
    "This will allow Ray to connect to the remote cluster.\\\n",
    "这将允许Ray连接到远程集群。\n",
    "\n",
    "Next, run the following command:\n",
    "```bash\n",
    "ray submit tune-default.yaml script.py\n",
    "ray submit tune-default.yaml script.py -- --ray-address=192.168.2.238:6379\n",
    "```\n",
    "\n",
    "The output should now look similar to the following:\n",
    "```bash\n",
    "This cluster consists of\n",
    "    3 nodes in total\n",
    "    6.0 CPU resources in total\n",
    "\n",
    "Tasks executed\n",
    "    3425 tasks on xxx.xxx.xxx.xxx\n",
    "    3834 tasks on xxx.xxx.xxx.xxx\n",
    "    2741 tasks on xxx.xxx.xxx.xxx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching Cloud Clusters\n",
    "[Launching Cloud Clusters](https://docs.ray.io/en/master/cluster/cloud.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local On Premise Cluster (List of nodes)\n",
    "\n",
    "You would use this mode if you want to run distributed Ray applications on some local nodes available on premise.\\\n",
    "如果您想在某些本地节点上运行分布式Ray应用程序，您可以使用这种模式。\n",
    "\n",
    "The most preferable way to run a Ray cluster on a private cluster of hosts is via the Ray Cluster Launcher.\\\n",
    "在主机的私有集群上运行Ray集群的最佳方式是通过Ray cluster Launcher。\n",
    "\n",
    "There are two ways of running private clusters:\\\n",
    "有两种方式运行私有集群:\n",
    "\n",
    "* Manually managed, i.e., the user explicitly specifies the head and worker ips.\\\n",
    "手动管理，即用户显式指定头ip和工人ip。\n",
    "* Automatically managed, i.e., the user only specifies a coordinator address to a coordinating server that automatically coordinates its head and worker ips.\\\n",
    "自动管理，即，用户只指定一个协调服务器的协调地址，自动协调它的头和工作ip。\n",
    "\n",
    "___\n",
    "**Tip**\n",
    "\n",
    "To avoid getting the password prompt when running private clusters make sure to setup your ssh keys on the private cluster as follows:\\\n",
    "为了避免在运行私有集群时出现密码提示，请确保在私有集群上设置ssh密钥如下：\n",
    "```bash\n",
    "$ ssh-keygen\n",
    "$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n",
    "```\n",
    "___\n",
    "\n",
    "You can get started by filling out the fields in the provided [ray/python/ray/autoscaler/local/example-full.yaml](https://github.com/ray-project/ray/tree/master/python/ray/autoscaler/local/example-full.yaml). Be sure to specify the proper `head_ip`, list of `worker_ips`, and the `ssh_user` field.\\\n",
    "您可以通过填写提供的[ray/python/ray/autoscaler/local/example-full.yaml](https://github.com/ray-project/ray/tree/master/python/ray/autoscaler/local/example-full.yaml)中的字段开始。请确保指定正确的`head_ip`、`worker_ips`列表和`ssh_user`字段。\n",
    "```bash\n",
    "vim ray/python/ray/autoscaler/local/example-full.yaml\n",
    "```\n",
    "\n",
    "```yaml\n",
    "# An unique identifier for the head node and workers of this cluster.\n",
    "cluster_name: default\n",
    "\n",
    "## NOTE: Typically for local clusters, min_workers == max_workers == len(worker_ips).\n",
    "\n",
    "# The minimum number of workers nodes to launch in addition to the head\n",
    "# node. This number should be >= 0.\n",
    "# Typically, min_workers == max_workers == len(worker_ips).\n",
    "min_workers: 3\n",
    "\n",
    "# The maximum number of workers nodes to launch in addition to the head node.\n",
    "# This takes precedence over min_workers.\n",
    "# Typically, min_workers == max_workers == len(worker_ips).\n",
    "max_workers: 3\n",
    "\n",
    "# The autoscaler will scale up the cluster faster with higher upscaling speed.\n",
    "# E.g., if the task requires adding more nodes then autoscaler will gradually\n",
    "# scale up the cluster in chunks of upscaling_speed*currently_running_nodes.\n",
    "# This number should be > 0.\n",
    "upscaling_speed: 1.0\n",
    "\n",
    "idle_timeout_minutes: 5\n",
    "\n",
    "# Local specific configuration.\n",
    "provider:\n",
    "    type: local\n",
    "    head_ip: 192.168.2.238\n",
    "    worker_ips: [192.168.2.17, 192.168.2.27]\n",
    "    # Optional when running automatic cluster management on prem. If you use a coordinator server,\n",
    "    # then you can launch multiple autoscaling clusters on the same set of machines, and the coordinator\n",
    "    # will assign individual nodes to clusters as needed.\n",
    "    #    coordinator_address: \"<host>:<port>\"\n",
    "\n",
    "# How Ray will authenticate with newly launched nodes.\n",
    "auth:\n",
    "    ssh_user: ubuntu\n",
    "    # Optional if an ssh private key is necessary to ssh to the cluster.\n",
    "    ssh_private_key: ~/.ssh/id_rsa\n",
    "\n",
    "# Leave this empty.\n",
    "head_node: {}\n",
    "\n",
    "# Leave this empty.\n",
    "worker_nodes: {}\n",
    "\n",
    "# Files or directories to copy to the head and worker nodes. The format is a\n",
    "# dictionary from REMOTE_PATH: LOCAL_PATH, e.g.\n",
    "file_mounts: {\n",
    "#    \"/path1/on/remote/machine\": \"/path1/on/local/machine\",\n",
    "#    \"/path2/on/remote/machine\": \"/path2/on/local/machine\",\n",
    "}\n",
    "\n",
    "# Files or directories to copy from the head node to the worker nodes. The format is a\n",
    "# list of paths. The same path on the head node will be copied to the worker node.\n",
    "# This behavior is a subset of the file_mounts behavior. In the vast majority of cases\n",
    "# you should just use file_mounts. Only use this if you know what you're doing!\n",
    "cluster_synced_files: []\n",
    "\n",
    "# Whether changes to directories in file_mounts or cluster_synced_files in the head node\n",
    "# should sync to the worker node continuously\n",
    "file_mounts_sync_continuously: False\n",
    "\n",
    "# Patterns for files to exclude when running rsync up or rsync down\n",
    "rsync_exclude:\n",
    "    - \"**/.git\"\n",
    "    - \"**/.git/**\"\n",
    "\n",
    "# Pattern files to use for filtering out files when running rsync up or rsync down. The file is searched for\n",
    "# in the source directory and recursively through all subdirectories. For example, if .gitignore is provided\n",
    "# as a value, the behavior will match git's behavior for finding and using .gitignore files.\n",
    "rsync_filter:\n",
    "    - \".gitignore\"\n",
    "\n",
    "# List of commands that will be run before `setup_commands`. If docker is\n",
    "# enabled, these commands will run outside the container and before docker\n",
    "# is setup.\n",
    "initialization_commands: []\n",
    "\n",
    "# List of shell commands to run to set up each nodes.\n",
    "setup_commands: []\n",
    "    # Note: if you're developing Ray, you probably want to create a Docker image that\n",
    "    # has your Ray repo pre-cloned. Then, you can replace the pip installs\n",
    "    # below with a git checkout <your_sha> (and possibly a recompile).\n",
    "    # To run the nightly version of ray (as opposed to the latest), either use a rayproject docker image\n",
    "    # that has the \"nightly\" (e.g. \"rayproject/ray-ml:nightly-gpu\") or uncomment the following line:\n",
    "    # - pip install -U \"ray[default] @ https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-2.0.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl\"\n",
    "\n",
    "# Custom commands that will be run on the head node after common setup.\n",
    "head_setup_commands: []\n",
    "\n",
    "# Custom commands that will be run on worker nodes after common setup.\n",
    "worker_setup_commands: []\n",
    "\n",
    "# Command to start ray on the head node. You don't need to change this.\n",
    "head_start_ray_commands:\n",
    "    - ray stop\n",
    "    - ulimit -c unlimited && ray start --head --port=6379 --autoscaling-config=~/ray_bootstrap_config.yaml\n",
    "\n",
    "# Command to start ray on worker nodes. You don't need to change this.\n",
    "worker_start_ray_commands:\n",
    "    - ray stop\n",
    "    - ray start --address=$RAY_HEAD_IP:6379\n",
    "```\n",
    "\n",
    "Test that it works by running the following commands from your local machine:\\\n",
    "通过在本地机器上运行以下命令来测试它的工作：\n",
    "```bash\n",
    "# Create or update the cluster. \n",
    "# When the command finishes, \n",
    "# it will print out the command that can be used to get a remote shell into the head node.\n",
    "$ ray up ray/python/ray/autoscaler/local/example-full.yaml\n",
    "\n",
    "# Get a remote screen on the head node.\n",
    "$ ray attach ray/python/ray/autoscaler/local/example-full.yaml\n",
    "# Try running a Ray program with 'ray.init(address=\"auto\")'.\n",
    "\n",
    "# Tear down the cluster\n",
    "$ ray down ray/python/ray/autoscaler/local/example-full.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Ray Cluster Setup\n",
    "\n",
    "The most preferable way to run a Ray cluster is via the Ray Cluster Launcher. However, it is also possible to start a Ray cluster by hand.\\\n",
    "运行射线集群的最佳方式是通过射线集群启动器。然而，也可以手动启动一个Ray集群。\n",
    "\n",
    "This section assumes that you have a list of machines and that the nodes in the cluster can communicate with each other. It also assumes that Ray is installed on each machine.\\\n",
    "本节假设您有一个机器列表，并且集群中的节点可以彼此通信。它还假设在每台机器上都安装了Ray。\n",
    "\n",
    "##### Starting Ray on each machine\n",
    "\n",
    "On the head node (just choose some node to be the head node), run the following. If the `--port` argument is omitted, Ray will choose port 6379, falling back to a random port.\\\n",
    "在头节点上(只需选择某个节点作为头节点)，运行以下命令。如果省略了`--port`参数，Ray将选择端口6379，返回到一个随机端口。\n",
    "```bash\n",
    "ray start --head\n",
    "```\n",
    "You should see somthing like:\n",
    "```bash\n",
    "Local node IP: 192.168.2.238\n",
    "2021-05-09 20:53:07,861\tINFO services.py:1262 -- View the Ray dashboard at http://127.0.0.1:8265\n",
    "\n",
    "--------------------\n",
    "Ray runtime started.\n",
    "--------------------\n",
    "\n",
    "Next steps\n",
    "  To connect to this Ray runtime from another node, run\n",
    "    ray start --address='192.168.2.238:6379' --redis-password='5241590000000000'\n",
    "  \n",
    "  Alternatively, use the following Python code:\n",
    "    import ray\n",
    "    ray.init(address='auto', _redis_password='5241590000000000')\n",
    "  \n",
    "  If connection fails, check your firewall settings and network configuration.\n",
    "  \n",
    "  To terminate the Ray runtime, run\n",
    "    ray stop\n",
    "```\n",
    "\n",
    "The command will print out the address of the Redis server that was started (the local node IP address plus the port number you specified).\\\n",
    "该命令将打印出启动的Redis服务器的地址(本地节点IP地址加上您指定的端口号)。\n",
    "\n",
    "\n",
    "**Then on each of the other nodes**, run the following. Make sure to replace `<address>` with the value printed by the command on the head node (it should look something like `123.45.67.89:6379`).\\\n",
    "**然后在每个其他节点上**，运行以下命令。确保将`<address>`替换为该命令在头节点上打印的值(它应该类似于`123.45.67.89:6379`)。\n",
    "```bash\n",
    "ray start --address=<address> --redis-password='<password>'\n",
    "ray start --address='192.168.2.238:6379' --redis-password='5241590000000000'\n",
    "```\n",
    "You should see something like this:\n",
    "```bash\n",
    "Local node IP: 192.168.2.238\n",
    "\n",
    "--------------------\n",
    "Ray runtime started.\n",
    "--------------------\n",
    "\n",
    "To terminate the Ray runtime, run\n",
    "  ray stop\n",
    "```\n",
    "\n",
    "If you wish to specify that a machine has 10 CPUs and 1 GPU, you can do this with the flags `--num-cpus=10` and `--num-gpus=1`.\\\n",
    "如果你想指定一台机器有10个cpu和1个GPU，你可以使用标记`--num-cpus=10`和`--num-gpus=1`来完成。\n",
    "\n",
    "If you see `Ray runtime started`, then the node successfully connected to the IP address at the `--port`. You should now be able to connect to the cluster with `ray.init(address='auto')`.\\\n",
    "如果你看到`Ray runtime started`，则节点成功连接到`--port`的IP地址。您现在应该能够使用`ray.init(address='auto')`连接到集群。\n",
    "\n",
    "Next, run the following command to test:\n",
    "```bash\n",
    "python3 script.py\n",
    "```\n",
    "The output should now look similar to the following:\n",
    "```bash\n",
    "2021-05-09 20:37:04,489\tINFO worker.py:663 -- Connecting to existing Ray cluster at address: 192.168.2.238:6379\n",
    "This cluster consists of\n",
    "    3 nodes in total\n",
    "    3.0 CPU resources in total\n",
    "\n",
    "Tasks executed\n",
    "    3475 tasks on 192.168.2.238\n",
    "    3646 tasks on 192.168.2.27\n",
    "    2879 tasks on 192.168.2.17\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAY TUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this example, install the following:\n",
    "```bash\n",
    "pip3 install 'ray[tune]'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Distributed Experiments\n",
    "[Tune Distributed Experiments](https://docs.ray.io/en/master/tune/tutorials/tune-distributed.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Cluster Setup\n",
    "\n",
    "If you already have a list of nodes, you can follow the local private cluster setup. Below is an example cluster configuration as `tune-default.yaml`:\\\n",
    "如果您已经有一个节点列表，那么您可以按照本地私有集群设置。下面是`tune-default.yaml`集群配置示例：\n",
    "```yaml\n",
    "cluster_name: local-default\n",
    "provider:\n",
    "    type: local\n",
    "    head_ip: YOUR_HEAD_NODE_HOSTNAME\n",
    "    worker_ips: [WORKER_NODE_1_HOSTNAME, WORKER_NODE_2_HOSTNAME, ... ]\n",
    "auth: {ssh_user: YOUR_USERNAME, ssh_private_key: ~/.ssh/id_rsa}\n",
    "## Typically for local clusters, min_workers == max_workers.\n",
    "min_workers: 3\n",
    "max_workers: 3\n",
    "setup_commands:  # Set up each node.\n",
    "    - pip install ray torch torchvision tabulate tensorboard\n",
    "```\n",
    "\n",
    "Create a `tune-default.yaml`:\n",
    "```bash\n",
    "sudo vim tune-default.yaml\n",
    "```\n",
    "with the example configuration:\n",
    "```yaml\n",
    "cluster_name: local-default\n",
    "provider:\n",
    "    type: local\n",
    "    head_ip: mengfeiliang-a3-m\n",
    "    worker_ips: [mengfeiliang-a3-w1, mengfeiliang-a3-w2]\n",
    "    cache_stopped_nodes: False\n",
    "auth: {ssh_user: ubuntu, ssh_private_key: ~/.ssh/id_rsa}\n",
    "## Typically for local clusters, min_workers == max_workers.\n",
    "min_workers: 3\n",
    "max_workers: 3\n",
    "setup_commands:  # Set up each node.\n",
    "    - pip3 install ray torch torchvision tabulate tensorboard\n",
    "```\n",
    "\n",
    "`ray up` starts Ray on the cluster of nodes.\\\n",
    "`ray up`在节点集群上启动ray。\n",
    "```bash\n",
    "ray up tune-default.yaml\n",
    "```\n",
    "\n",
    "`ray submit` uploads `tune_script.py` to the cluster and runs `python tune_script.py [args]`.\\\n",
    "`ray submit`上传`tune_script.py`到集群并运行`python tune_script.py [args]`。\n",
    "```bash\n",
    "ray submit tune-default.yaml tune_script.py -- --ray-address=localhost:6379\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune API Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn API (tune.sklearn)\n",
    "\n",
    "[Scikit-Learn API (tune.sklearn)](https://docs.ray.io/en/master/tune/api_docs/sklearn.html)\n",
    "\n",
    "```bash\n",
    "python3 tune_script.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEVELOPMENT AND RAY INTERNALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Ray from Source\n",
    "[Building Ray from Source](https://docs.ray.io/en/master/development.html#building-ray-python-only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Ray (Python Only)\n",
    "\n",
    "1. Pip install the latest Ray wheels.\n",
    "```bash\n",
    "pip3 install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-2.0.0.dev0-cp38-cp38-manylinux2014_x86_64.whl\n",
    "```\n",
    "\n",
    "2. Fork and clone the project to your machine. Connect your repository to the upstream (main project) ray repository.\n",
    "```bash\n",
    "git clone https://github.com/[your username]/ray.git\n",
    "cd ray\n",
    "git remote add upstream https://github.com/ray-project/ray.git\n",
    "# Make sure you are up-to-date on master.\n",
    "```\n",
    "\n",
    "3. Replace Python files in the installed package with your local editable copy. We provide a simple script to help you do this: `python python/ray/setup-dev.py`. Running the script will remove the `ray/tune`, `ray/rllib`, `ray/autoscaler` dir (among other directories) bundled with the `ray` pip package, and replace them with links to your local code. This way, changing files in your git clone will directly affect the behavior of your installed ray.\\\n",
    "用本地可编辑副本替换安装包中的Python文件。我们提供了一个简单的脚本来帮助你做到这一点：`python python/ray/setup-dev.py`。运行该脚本将删除与`ray` pip包绑定的`ray/tune`，`ray/rllib`，`ray/autoscaler`目录(以及其他目录)，并将它们替换为指向本地代码的链接。这样，改变文件在你的git克隆将直接影响你安装的ray的行为。\n",
    "___\n",
    "**Warning**\n",
    "\n",
    "Do not run `pip uninstall ray` or `pip install -U` (for Ray or Ray wheels) if setting up your environment this way. To uninstall or upgrade, you must first `rm -rf` the pip-installation site (usually a site-packages/ray location), then do a pip reinstall (see 1. above), and finally run the above `setup-dev.py` script again.\\\n",
    "如果以这种方式设置环境，请不要运行`pip uninstall ray`或`pip install -U`(用于ray或ray wheels)。要卸载或升级，您必须首先`rm -rf` pip安装位置(通常是`site-packages/ray`位置)，然后进行pip重新安装(参见1。最后再次运行上面的`setup-dev.py`脚本。\n",
    "\n",
    "```bash\n",
    "rm -rf /home/ubuntu/.local/lib/python3.8/site-packages/ray\n",
    "```\n",
    "___\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/ray-project/ray.git\n",
    "cd ray\n",
    "python3 python/ray/setup-dev.py\n",
    "# This replaces miniconda3/lib/python3.7/site-packages/ray/tune\n",
    "# with your local `ray/python/ray/tune`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Ray on Linux (full)\n",
    "\n",
    "To build Ray, first install the following dependencies.\n",
    "\n",
    "For Ubuntu, run the following commands:\n",
    "```bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y build-essential curl unzip psmisc\n",
    "\n",
    "pip3 install cython==0.29.0 pytest\n",
    "```\n",
    "\n",
    "Ray can be built from the repository as follows.\n",
    "```bash\n",
    "git clone https://github.com/ray-project/ray.git\n",
    "\n",
    "# Install Bazel.\n",
    "# (Windows users: please manually place Bazel in your PATH, and point BAZEL_SH to MSYS2's Bash.)\n",
    "ray/ci/travis/install-bazel.sh\n",
    "\n",
    "# (requires Node.js, see https://nodejs.org/ for more information).\n",
    "sudo apt-get install nodejs\n",
    "sudo apt-get install npm\n",
    "# Build the dashboard\n",
    "pushd ray/dashboard/client\n",
    "npm install\n",
    "npm run build\n",
    "popd\n",
    "\n",
    "# Install Ray.\n",
    "cd ray/python\n",
    "pip3 install -e . --verbose  # Add --user if you see a permission denied error.\n",
    "pip3 install -e . --verbose --user\n",
    "```\n",
    "\n",
    "The `-e` means “editable”, so changes you make to files in the Ray directory will take effect without reinstalling the package.\n",
    "\n",
    "___\n",
    "**Warning**\n",
    "\n",
    "if you run `python setup.py install`, files will be copied from the Ray directory to a directory of Python packages (`/lib/python3.6/site-packages/ray`). This means that changes you make to files in the Ray directory will not have any effect.\\\n",
    "如果运行`python setup.py install`，文件将从Ray目录复制到包含python包的目录(`/lib/python3.6/site-packages/Ray`)。这意味着您对Ray目录中的文件所做的更改不会有任何效果。\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
