{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kafka vs. Pulsar vs. RabbitMQ: Performance, Architecture, and Features Compared\n",
    "[Kafka vs. Pulsar vs. RabbitMQ: Performance, Architecture, and Features Compared](https://www.confluent.io/kafka-vs-pulsar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Consumption Model\n",
    "\n",
    "Kafka uses a pull-based architecture where consumers pull messages from the server and long-polling is used to ensure new messages are made available instantaneously.\\\n",
    "Kafka使用一种基于拉的架构，消费者从服务器拉出消息，并使用长轮询来确保新消息即时可用。\n",
    "\n",
    "RabbitMQ uses a push-based approach synonymous with traditional messaging systems.\\\n",
    "RabbitMQ使用的是一种与传统消息系统相同的基于推的方式。\n",
    "\n",
    "Pulsar also uses a push-based approach but with an API that simulates consumer pulls.\\\n",
    "Pulsar也使用了基于推的方法，但是使用了一个模拟消费者拉动的API。\n",
    "\n",
    "Pull based architectures are often preferable for high throughput workloads as they allow consumers to manage their own flow control, essentially fetching only what they need. Push based architectures require flow control and backpressure to be integrated into the broker.\\\n",
    "基于拉的架构通常更适合于高吞吐量的工作负载，因为它们允许使用者管理自己的流控制，本质上只获取他们需要的内容。基于推送的架构需要将流控制和反压力集成到代理中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Architecture\n",
    "\n",
    "Kafka uses a distributed commit log as its storage layer. Writes are appended to the end of the log. Reads are sequential starting from an offset and data is zero-copied from the disk buffer to the network buffer. This works well for event streaming use cases.\\\n",
    "Kafka使用分布式提交日志作为其存储层。写操作追加到日志的末尾。读取是从偏移量开始的顺序读取，数据从磁盘缓冲区零拷贝到网络缓冲区。这对于事件流用例很有效。\n",
    "\n",
    "Conversely, RabbitMQ and Pulsar both use index-based storage systems. These keep data in a tree structure to provide the fast access necessary for acknowledging individual messages. The fast individual reads that tree structures provide come at the cost of write overhead, which can manifest as either decreased write throughput, increased write latency, or increased write amplification compared to a log. RabbitMQ and Pulsar differ in the design of the storage layer also. RabbitMQ is designed to store messages for a short period of time only. Pulsar like Kafka can retain messages indefinitely.\\\n",
    "相反，RabbitMQ和Pulsar都使用基于索引的存储系统。它们将数据保存在树形结构中，以提供确认单个消息所需的快速访问。树结构提供的快速单个读取是以写开销为代价的，与日志相比，写开销可以表现为写吞吐量降低、写延迟增加或写放大增加。RabbitMQ和Pulsar在存储层的设计上也有所不同。RabbitMQ被设计成只存储短时间的消息。像Kafka这样的Pulsar可以无限期地保留信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ease of Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational Simplicity\n",
    "\n",
    "Kafka is a cluster-based technology with a medium-weight architecture requiring two distributed components: Kafka's own servers (brokers) plus ZooKeeper™ servers. Zookeeper adds an additional level of complexity but the community is in the process of removing the ZooKeeper component from Kafka which will significantly decrease Kafka's operational burden. The Kafka ecosystem includes two different mature Kubernetes operators, one open source and one commercial. These ease cluster management significantly.\\\n",
    "Kafka是一种基于集群的技术，具有中等重量的架构，需要两个分布式组件:Kafka自己的服务器(broker)和ZooKeeper™服务器。Zookeeper增加了额外的复杂性，但是社区正在从Kafka中移除Zookeeper组件，这将显著降低Kafka的操作负担。Kafka生态系统包括两个不同的成熟Kubernetes运营商，一个开源，一个商业。这大大简化了集群管理。\n",
    "\n",
    "Pulsar has a heavy-weight architecture that is the most complex in this comparison. It requires four components be configured and understood: Pulsar servers (brokers) plus Apache BookKeeper (bookies) plus Apache ZooKeeper servers as well as the RocksDB database used by BookKeeper.\\\n",
    "在这个比较中，Pulsar的结构是最复杂的。它需要配置和理解四个组件：Pulsar服务器（broker）加上Apache BookKeeper (bookies)加上Apache ZooKeeper服务器以及BookKeeper使用的RocksDB数据库。\n",
    "\n",
    "RabbitMQ has a comparatively light-weight architecture, requiring only RabbitMQ's own servers (brokers). However it's distributed configurations are less complete and often more complex to manage compared to Kafka and Pulsar (e.g. the sharding plugin). RabbitMQ is currently without a production-grade Kubernetes operator (although a commercial one is in the works).\\\n",
    "RabbitMQ是一个相对轻量级的架构，只需要RabbitMQ自己的服务器（broker）。然而，与Kafka和Pulsar（例如sharding插件）相比，它的分布式配置不那么完整，而且管理起来往往更复杂。RabbitMQ目前还没有一个生产级Kubernetes运营商（尽管一个商业运营商正在开发中）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance & availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throughput, Latency, and Scale\n",
    "\n",
    "Kafka provides the highest throughput and lowest latency of all three systems, based on measurements taken using the Open Messaging Benchmark configured for a typical event streaming use case. Its ability to operate at network-speeds and to process trillions of events (messages) per day has been demonstrated in production by power users such as Netflix, LinkedIn, Uber, Microsoft, Twitter, and Tencent. Large Kafka deployments can consist of hundreds of servers or more.\\\n",
    "Kafka提供了三个系统中最高的吞吐量和最低的延迟，这是基于一个典型的事件流用例配置的开放消息基准所采取的测量。Netflix、LinkedIn、Uber、微软、Twitter和腾讯等超级用户已经在生产中证明了它以网络速度运行，每天处理数万亿事件(消息)的能力。大型Kafka部署可以包含数百台甚至更多的服务器。\n",
    "\n",
    "Pulsar, by comparison, has good scalability properties but is limited by its comparatively complex storage architecture. This means that, for the same resources, it cannot match Kafka's high-end throughput (this complexity and the associated cost is why Twitter abandoned their own BookKeeper-based system, similar in architecture to Pulsar, in favor of Kafka).\\\n",
    "相比之下，Pulsar具有良好的可扩展性，但存储结构相对复杂。这意味着，对于相同的资源，它不能匹配Kafka的高端吞吐量（这种复杂性和相关的成本是为什么Twitter放弃了他们自己的基于簿记账的系统，类似于Pulsar的架构，而支持Kafka）。\n",
    "\n",
    "RabbitMQ can benchmark at millions of messages per second, but real-world performance tends to be many orders of magnitude lower, particularly if datasets exceed the memory available. Also, RabbitMQ does not provide first-class distributed systems primitives like sharding, distributed consumption, or data balancing in the same seamless way Kafka and Pulsar do. All three technologies provide broadly similar latencies.\\\n",
    "RabbitMQ可以以每秒数百万条消息为基准，但现实世界的性能往往要低很多个数量级，特别是当数据集超过可用内存时。此外，RabbitMQ不像Kafka和Pulsar那样提供一流的分布式系统原语，如分片、分布式消费或数据平衡。这三种技术都提供了大致相似的延迟。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Availability\n",
    "\n",
    "All three systems include high-availability features.\\\n",
    "这三个系统都包含高可用性特性。\n",
    "\n",
    "Kafka and Pulsar both provide seamless availability with sharded partitions, which are also replicated for high availability across machines or availability zones.\\\n",
    "Kafka和Pulsar都通过分片分区提供了无缝可用性，分片分区也可以跨机器或可用区域复制高可用性。\n",
    "\n",
    "RabbitMQ has a plugin for sharding and supports mirroring, but the result is less seamless than the other two.\\\n",
    "RabbitMQ有一个分片插件，支持镜像，但结果不如其他两个无缝。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Data Replication\n",
    "\n",
    "All three technologies include features for global data replication. This could be, between two datacenters or between two geo-regions in the cloud. Kafka and Pulsar both replicate in parallel allowing high throughput geo-replication.\\\n",
    "这三种技术都包括用于全局数据复制的特性。这可能是在两个数据中心之间或在云中的两个地理区域之间。Kafka和Pulsar都并行复制，允许高吞吐量的地理复制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering Guarantees\n",
    "\n",
    "Kafka provides strong ordering guarantees at a partition level even when consuming a topic in parallel across many consumers. RabbitMQ provides strong ordering for publish-subscribe and single-consumer topics but queues subscribed to by multiple consumers may break ordering guarantees. Ordering violations are also possible in Pulsar's 'shared' and Kafka-like 'key-shared' modes.\\\n",
    "Kafka在分区级别上提供了强大的排序保证，即使在多个消费者同时消费一个主题时也是如此。RabbitMQ为publish-subscribe和single-consumer主题提供了强排序，但是多个消费者订阅的队列可能会破坏排序保证。在Pulsar的“共享”和Kafka式的“密钥共享”模式中也可能存在顺序违反。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permanent Storage\n",
    "\n",
    "Kafka stores your data durably and reliably much like a normal database. Data retention is user configurable per Kafka topic. Companies like The New York Times store data forever in Kafka and use it as the source-of-truth for their business. Kafka features like topic compaction make such setups more efficient. Tiered Storage via KIP-405 further reduces the costs of long-term storage.\\\n",
    "Kafka像一个正常的数据库一样持久和可靠地存储你的数据。数据保留是用户可配置的每个Kafka主题。像《纽约时报》这样的公司将数据永远存储在Kafka中，并将其作为他们业务的真相来源。Kafka的特性，如主题压缩，使这样的设置更有效。通过KIP-405的分层存储进一步降低了长期存储的成本。\n",
    "\n",
    "RabbitMQ is different: by design, messages are removed once they are consumed and are not stored beyond that. So while RabbitMQ can store data, it is not designed to be held permanently.\\\n",
    "RabbitMQ则不同:根据设计，消息一旦被使用就会被删除，并且不会被存储。因此，虽然RabbitMQ可以存储数据，但它并不是被设计成永久保存的。\n",
    "\n",
    "Pulsar is also designed to delete messages once they have been consumed but unlike RabbitMQ can store data for longer in its BookKeeper storage layer. Bookkeeper's retention capabilities are limited by the fine-grained metadata it stores in Zookeeper.\\\n",
    "Pulsar也被设计用来在消息被消费后删除消息，但与RabbitMQ不同的是，Pulsar可以在它的BookKeeper存储层中存储更长的数据。Bookkeeper的保留能力受到它存储在Zookeeper中的细粒度元数据的限制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Stream Processing\n",
    "\n",
    "Kafka is the only technology that ships with functionality for stream processing. Its Kafka Streams library allows developers to implement elastic and scalable client applications that can leverage essential stream processing features such as tables, joins, aggregations, windowing, state management, fault-tolerance, security functionality, elastic scaling of client applications and exactly-once processing. The Kafka Streams ecosystem includes further tools for application development, including the Spring framework and ksqlDB an event streaming database built for Kafka.\\\n",
    "Kafka是唯一提供流处理功能的技术。它的Kafka流库允许开发人员实现弹性和可伸缩的客户端应用程序，可以利用基本的流处理特性，如表，连接，聚合，窗口，状态管理，容错，安全功能，客户端应用程序的弹性伸缩和精确一次处理。Kafka流生态系统包括进一步的应用开发工具，包括Spring框架和为Kafka构建的事件流数据库ksqlDB。\n",
    "\n",
    "In comparison, Pulsar provides only basic functionality for stream processing using its Pulsar Functions interface. This is suited to simple callbacks, but it isn't a true stream processing offering.\\\n",
    "相比之下，Pulsar只提供了基本的功能流处理使用Pulsar功能接口。这适合于简单的回调，但它不是真正的流处理产品。\n",
    "\n",
    "RabbitMQ provides no native stream processing features but can be integrated with external processing engines like Apache Flink®.\\\n",
    "RabbitMQ没有提供本地流处理特性，但可以与Apache Flink®等外部处理引擎集成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Replay, Time Travel\n",
    "\n",
    "Because both Kafka and Pulsar can store data permanently, they support use cases that a traditional messaging broker cannot. Data can be processed and reprocessed as needed to facilitate A/B testing, train analytic models, capture audit trails, recompute data due to (say) an application bug that produced incorrect results, and so forth. RabbitMQ can replay messages that have not been acknowledged, but the number of messages that can be retained and replayed efficiently is small in comparison to that of Kafka and Pulsar.\\\n",
    "因为Kafka和Pulsar都可以永久地存储数据，它们支持传统消息代理不能支持的用例。可以根据需要对数据进行处理和再处理，以促进A/B测试、训练分析模型、捕获审计跟踪、由于(比如)产生不正确结果的应用程序错误而重新计算数据，等等。RabbitMQ可以重放未被确认的消息，但是可以被保留和有效重放的消息数量比Kafka和Pulsar要少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exactly Once Processing\n",
    "\n",
    "Pulsar supports idempotent ([ai'dempətənt]) writes—meaning that duplicate messages are not stored in Pulsar's storage layer, but it does not support the transactional reads needed for exactly once (aka Effectively once) processing. For example, Pulsar cannot guarantee exactly-once semantics when messages are read and then written to a secondary topic, which is a common requirement for many practical use cases.\\\n",
    "Pulsar支持幂等的（idempotent）写操作——这意味着重复的消息不会存储在Pulsar的存储层中，但是它不支持事务读只需要一次处理（也就是有效一次）。例如，当在消息被读然后被写到一个次要主题时，Pulsar不能保证精确一次语义，这是许多实际用例的常见需求。\n",
    "\n",
    "Kafka supports at-most-once, at-least-once, and also high-throughput exactly once semantics specifically aimed at end-to-end stream processing use cases (Kafka Streams) and exactly-once enabled connectors (Kafka Connect). This is achieved with a combination of both idempotent writes to Kafka and its transaction API.\\\n",
    "Kafka支持最多一次，至少一次，并且高吞吐量精确一次的语义，专门针对端到端流处理用例（Kafka流）和精确一次的连接器（Kafka Connect）。这是通过对Kafka和它的事务API的幂等写入来实现的。\n",
    "\n",
    "RabbitMQ does not include transactions or idempotence in the broker, meaning it supports only at-least-once semantics.\\\n",
    "RabbitMQ不包括事务或幂等，这意味着它只支持“至少一次”语义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic (Log) Compaction\n",
    "\n",
    "Kafka supports native topic compaction, which runs on all brokers. This runs automatically for compacted topics, condensing the log down to the latest version of messages sharing the same key.\\\n",
    "Kafka支持本地主题压缩，它可以在所有代理上运行。这将自动运行压缩主题，将日志压缩到共享相同密钥的最新版本的消息。\n",
    "\n",
    "Pulsar supports a similar feature, but it runs over the network, streaming data from the storage layer to the broker layer, running compaction, then saving the result back. It also does not work in the same seamless way but instead creates a “snapshot” of a topic compacted at some prior point in time (with the original topic remaining).\\\n",
    "Pulsar支持类似的特性，但它通过网络运行，将数据从存储层流到代理层，运行压缩，然后将结果保存回来。它也不能以相同的无缝方式工作，而是在之前的某个时间点创建一个主题的“快照”(保留原来的主题)。\n",
    "\n",
    "RabbitMQ does not support topic compaction.\\\n",
    "RabbitMQ不支持主题压缩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission Critical\n",
    "\n",
    "Kafka is used by tens of thousands of organizations across a plethora of industries, including more than 80% of Fortune 100 companies. Examples include mission-critical use cases spanning stock exchanges, internet, telco, retail, car-sharing, banking and insurance, automotive, healthcare, manufacturing, news and media, gaming, and many more.\\\n",
    "Kafka被数以万计的行业组织使用，包括超过80%的财富100强公司。示例包括任务关键型用例，包括股票交易所、互联网、电信、零售、汽车共享、银行和保险、汽车、医疗保健、制造、新闻和媒体、游戏等等。\n",
    "\n",
    "RabbitMQ is a popular traditional messaging system and, similar to Kafka, is widely used across industries in mission-critical applications. Examples include telcos, banks and insurances, retail, Internet companies, logistics, and more.\\\n",
    "RabbitMQ是一个流行的传统消息系统，和Kafka类似，在关键任务的应用中广泛使用。例子包括电信、银行和保险、零售、互联网公司、物流等。\n",
    "\n",
    "Pulsar has significantly less adoption compared to Kafka or RabbitMQ, but there are production use cases notably at Yahoo where the project initiated and in China. Examples include online retail, media, and web hosting companies. Pulsar lacks public mission-critical use cases.\\\n",
    "与Kafka或RabbitMQ相比，Pulsar的应用明显较少，但在项目启动的雅虎(Yahoo)和中国有一些明显的生产用例。例子包括在线零售、媒体和虚拟主机公司。Pulsar缺乏公共关键任务用例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Streaming\n",
    "\n",
    "Kafka provides the rich suite of tools required for event streaming use cases, a category it helped define. These include strongly ordered parallel message delivery, message storage that decouples consumers from the rate of input events, and rich features for processing events and creating streaming pipelines.\\\n",
    "Kafka为事件流用例提供了丰富的工具套件，它帮助定义了一个类别。这包括强排序的并行消息传递、将使用者与输入事件的速率解耦的消息存储，以及用于处理事件和创建流管道的丰富特性。\n",
    "\n",
    "RabbitMQ lacks the ordered parallel message delivery properties needed for such use cases.\\\n",
    "RabbitMQ缺少这些用例所需的有序并行消息传递属性。\n",
    "\n",
    "Pulsar does better in this category but lacks the strong guarantees needed for event streaming pipelines.\\\n",
    "Pulsar在这方面做得更好，但缺乏事件流管道所需的强大保证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Routing\n",
    "\n",
    "As a mature traditional messaging system, RabbitMQ has an extensive set of server-side (i.e., broker-side) message routing capabilities via the routing keys and exchanges described in the AMQP protocol.\\\n",
    "作为一个成熟的传统消息系统，RabbitMQ通过AMQP协议中描述的路由密钥和交换，拥有大量的服务器端（即broker端）消息路由功能。\n",
    "\n",
    "Kafka provides similar capabilities through Kafka Connect and Kafka Streams, including content-based routing, message transformation, and message enrichment. Unlike RabbitMQ these components run in a separate layer.\\\n",
    "Kafka通过Kafka Connect和Kafka Streams提供了类似的功能，包括基于内容的路由、消息转换和消息充实。与RabbitMQ不同，这些组件运行在一个单独的层中。\n",
    "\n",
    "Pulsar is similar to Kafka in this regard but with more limited routing capabilities in its Pulsar Functions processing layer. But like RabbitMQ, Pulsar runs its Pulsar Functions inside the broker.\\\n",
    "Pulsar在这方面与Kafka相似，但其Pulsar Functions处理层的路由能力更有限。但与RabbitMQ一样，Pulsar也在broker中运行Pulsar函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Queuing\n",
    "\n",
    "RabbitMQ supports message queuing via AMQP e.g., for implementing a worker queue that delivers messages round-robin to competing consumers. Kafka focuses on event streaming and delivers messages based on the order of messages in a partition. Kafka's consumer groups feature provides a model similar to competing consumers. Pulsar also supports a queuing API that provides the highest offset delivery similar to RabbitMQ, though it is limited in comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Apache Kafka and Apache Pulsar\n",
    "[Comparing Apache Kafka and Apache Pulsar](https://blog.softwaremill.com/comparing-apache-kafka-and-apache-pulsar-3bd44e00f304)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Apache Pulsar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sounds familiar. And there are more similarities — Pulsar Functions (sounds like Kafka Streams), horizontal scalability, strong durability guarantees, geo-replication, authentication, authorisation and quotas, client libraries and operations utilities. One thing that is fundamentally different is the persistent storage. While in Kafka logs are persisted on the brokers, Pulsar uses Apache BookKeeper — more on this later.\\\n",
    "听起来很熟悉。还有更多相似之处——Pulsar Functions（听起来像Kafka Streams），水平可扩展性，强大的耐久性保证，地理复制，认证，授权和配额，客户端库和操作工具。一个本质上不同的东西是持久存储。在Kafka中，日志是持久化在代理上的，而Pulsar使用的是Apache BookKeeper——稍后会详细介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage model differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although both systems are designed to store messages for an infinite period of time, they differ w.r.t. (= with regard to) the layer where messages are stored. Kafka uses a log that is distributed among brokers which form a cluster. Pulsar delegates persistence to another system called Apache BookKeeper. This seems to be a real advantage especially when it comes to scaling, as explained a bit later. Another tempting feature of BookKeeper is tiered storage. Old and less frequently used data can be put on slower and more cost effective storage like Amazon S3. Storage space can be extended as much as your money bag allows for it.\\\n",
    "尽管这两种系统都设计为无限长的时间内存储消息，但它们在存储消息的层上是不同的。Kafka使用的日志分布在形成集群的broker之间。Pulsar将持久性委托给另一个名为Apache BookKeeper的系统。这似乎是一个真正的优势，特别是当涉及到扩展时，后面会解释。BookKeeper的另一个诱人的特点是分层存储。旧的和不经常使用的数据可以放在更慢、更划算的存储上，比如Amazon S3。储存空间可以在你的钱袋允许的范围内扩展。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message consumption flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kafka is a streaming platform. It has the concept of topic partitioning which allows parallel consumption on the topic level and guarantees ordering at the partition level.\\\n",
    "Kafka是一个流媒体平台。它具有主题分区的概念，允许在主题层上并行使用，并保证在分区层上排序。\n",
    "\n",
    "However you cannot distribute the load by simply adding more consumers. The number is limited by the number of partitions and you should plan ahead and over-partition by default, since increasing the number of partitions later on may be tricky when message keys play a role in ordering or when uneven partitions need to be rebalanced.\\\n",
    "然而，您不能通过简单地添加更多的使用者来分配负载。分区的数量受分区数量的限制，默认情况下，您应该提前计划，并且分区过多，因为当消息键在排序中发挥作用时，或者当不均匀的分区需要重新平衡时，以后增加分区的数量可能会很棘手。\n",
    "\n",
    "Kafka was not designed to be a queue though. It does not allow to acknowledge individual messages, but only up to a point, called the watermark.\\\n",
    "但是Kafka并不是被设计成一个队列的。它不允许确认单个消息，但只允许在一个称为watermark的点上确认。\n",
    "\n",
    "This is where Pulsar shines. It has four different kinds of message consumption concepts also known as subscriptions.\\\n",
    "这就是Pulsar发光的地方。它有四种不同的消息消费概念，也称为订阅。\n",
    "* `Exclusive` and `failover` subscriptions are covering the streaming use cases, where ordering per partition is required.\n",
    "* A `shared` subscription on the other hand allows to throw in many so called competing consumers for a given partition to parallelize the processing of stored messages. A typical use case where a queue is required. This has been explained in a very detailed comparison of Kafka’s and Pulsar’s messaging model.\n",
    "* The last kind of a subscription is `key_shared`, where as in shared mode multiple consumers can fetch messages, but messages with a particular key will be processed on only one consumer. This approach does not require the topic to be partitioned. Be aware though there is an open issue making this type of subscription useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ease of scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory it’s possible to scale up and down a Kafka cluster by adding or shutting down nodes. However if a Kafka cluster loses a node, it expects it to come back online soon and does not perform any re-balancing of existing partitions. Same is true when adding a node. Kafka doesn’t move data automatically to new brokers, which results in unbalanced leaders and disk utilisation across brokers. The confluent-rebalancer tool and the commercial Confluent Auto Data Balancer can restore balance in a cluster and you need to get familiar with those. Downscaling a Kafka cluster deployed on Amazon MSK is not supported at all.\\\n",
    "从理论上讲，可以通过增加或关闭节点来扩展和缩小Kafka集群。然而，如果一个Kafka集群丢失了一个节点，它会希望它很快恢复在线，并且不会对现有的分区进行任何重新平衡。添加节点时也是如此。Kafka不会自动将数据移动到新的broker，这将导致leader和磁盘使用率不平衡。Confluent -rebalancer工具和商业Confluent自动数据平衡器可以恢复集群中的平衡，您需要熟悉它们。不支持在Amazon MSK上部署Kafka集群。\n",
    "\n",
    "Pulsar brokers on the other hand are stateless — they are not responsible for storing messages on their local disk. Therefore spinning up or tearing down brokers is much less of a hassle.\\\n",
    "另一方面，Pulsar broker是无状态的——它们不负责将消息存储在本地磁盘上。因此，拆散或拆散broker的麻烦要小得多。\n",
    "\n",
    "The separation between brokers and the storage allows to scale these two layers independently. If you require more disk space to store more or bigger messages, you scale only BookKeeper. If you have to serve more clients, just add more Pulsar brokers. With Kafka, adding a broker means extending the storage capacity as well as serving capabilities.\\\n",
    "broker和存储之间的分离允许独立地扩展这两个层。如果您需要更多的磁盘空间来存储更多或更大的消息，则只需扩展BookKeeper。如果你要服务更多的client，就增加更多的Pulsar broker。对于Kafka，添加broker意味着扩展存储容量和服务能力。\n",
    "\n",
    "Other issues may arise when you have a lot of partitions. In Kafka terms a lot means ~200 000. The more partitions, the more opened file handles, increased unavailability when leader election is triggered by an unclean shutdown of a node and higher end-to-end latency due to replication. Pulsar on the other hand promises to scale up to millions of topics. It supports partitioned topics as internal topics, one per partition. But since most of the mentioned issues are related to the way how data is stored, Pulsar is not affected by them. I wonder however, how Bookkeeper deals with these problems.\\\n",
    "当您有很多分区时，可能会出现其他问题。用Kafka的话来说，很多意味着20万左右。分区越多，打开的文件句柄就越多，当节点不干净地关闭触发leader选举时，不可用性就会增加，复制导致的端到端延迟也会增加。另一方面，Pulsar有望扩大到数以百万计的主题。它支持将分区主题作为内部主题，每个分区一个。但由于上述问题大多与数据存储方式有关，因此Pulsar不受影响。然而，我不知道Bookkeeper是如何处理这些问题的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining technical differences between Apache Kafka and Apache Pulsar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo-replication\n",
    "\n",
    "Built into Pulsar, it allows to protect against entire data center failures, as well as increase responsiveness for clients located in different parts of the world. With Kafka you have to rely on additional tooling like uReplicator, MirrorMaker2 or Confluent’s Multi-Region Clusters and Replicator.\\\n",
    "它内置在Pulsar中，可以防止整个数据中心发生故障，并提高位于世界各地的client的响应能力。使用Kafka，你必须依赖额外的工具，如uReplicator, MirrorMaker2或Confluent的多区域集群和Replicator。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka vs Apache Pulsar\n",
    "[Apache Kafka vs Apache Pulsar](https://digitalis.io/blog/kafka/apache-kafka-vs-apache-pulsar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Core Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brokers\n",
    "\n",
    "Within both Kafka and Pulsar is a broker architecture, these handle incoming messages from producers and then handle the messages that are handled by the consumers. When it comes to the messages, with Kafka the messages are pulled from the Kafka brokers to the consumers. In Pulsar it’s the other way around, they are pushed to the subscribing consumers.\\\n",
    "Kafka和Pulsar都是broker架构，它们处理来自生产者的传入消息，然后处理由消费者处理的消息。说到消息，Kafka的消息是从Kafka broker拉到消费者的。而在脉冲星则相反，它们被推给了订阅用户。\n",
    "\n",
    "One of the major advantages of Pulsar over Kafka is around the number of topics you can produce. There are hard limitations on a Kafka cluster when it comes to partitions, a limit of 4000 partitions per broker and a total of 200,000 across the entire cluster, there will be a time when you cannot create more topics. Pulsar doesn’t suffer from this limitation, you can scale with millions of topics as the data is not stored within the brokers themselves but externally in Bookkeeper nodes.\\\n",
    "与Kafka相比，Pulsar的主要优势之一是你可以产生的主题的数量。Kafka集群在分区方面有严格的限制，每个broker的分区限制是4000，整个集群的分区限制是20万，总有一天你不能创建更多的主题。Pulsar不受这种限制，您可以扩展数以百万计的主题，因为数据不是存储在broker本身中，而是存储在外部的Bookkeeper节点中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zookeeper\n",
    "\n",
    "Both systems use Apache Zookeeper for cluster coordination. Kafka, at present, uses Zookeeper for metadata on topic configuration and access control lists (ACLs), Pulsar uses Zookeeper for the same purposes.\\\n",
    "这两个系统都使用Apache Zookeeper进行集群协调。Kafka目前使用Zookeeper作为主题配置和访问控制列表（ACLs）的元数据，Pulsar也使用Zookeeper来实现相同的目的。\n",
    "\n",
    "With KIP-500 improvement proposal, the removal of Zookeeper in Kafka will happen – it’s currently being tested. This means that Kafka will operate on it’s own, only relying on the operating brokers for all the cluster metadata. It’s worth noting that Kafka can still be run in “legacy mode” if you still want to have Zookeeper handle its metadata.\\\n",
    "根据KIP-500的改进方案，Kafka中Zookeeper的移除将会发生——目前正在测试中。这意味着Kafka将自己操作，只依赖于操作代理的所有集群元数据。值得注意的是，如果你仍然想让Zookeeper处理它的元数据，Kafka仍然可以在“遗留模式”下运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Data Center Replication\n",
    "\n",
    "For me Pulsar wins the replication battle, it provides geo-replication out of the box. A replicated cluster can be created across multiple data centers. Applications can be blocked from consuming from local clusters until messages have been replicated and acknowledged.\\\n",
    "对我来说，Pulsar赢得了复制战，它提供了立即可用的geo-replication。复制的集群可以跨多个数据中心创建。在复制并确认消息之前，可以阻止应用程序从本地集群消费消息。\n",
    "\n",
    "Kafka has two methods for replication, Mirror Maker 2 or Confluent Replicator. If you are using the Apache Kafka distribution then you have Mirror Maker 2, it works well but takes time to configure. If you have purchased a Confluent licence then Replicator is available to you as a standalone application or a connector running on a Kafka Connect node.\\\n",
    "Kafka有两种复制方法，Mirror Maker 2或Confluent Replicator。如果你正在使用Apache Kafka发行版，那么你有Mirror Maker 2，它工作得很好，但需要时间来配置。如果你已经购买了Confluent许可证，那么Replicator可以作为一个独立的应用程序或Kafka Connect节点上的连接器提供给你。\n",
    "\n",
    "\n",
    "Offset handling is incredibly difficult to achieve with replicated Kafka, with some custom API coding required in applications to read from the replicated cluster. Pulsar doesn’t suffer from these problems. It’s worth pointing out that multi DC operation is coming to the Confluent Platform in the future but will be part of the paid for licence.\\\n",
    "用复制的Kafka来实现偏移量处理是非常困难的，应用程序需要一些自定义API代码来从复制的集群中读取数据。Pulsar没有这些问题。值得指出的是，多直流操作将在未来进入Confluent平台，但将成为付费许可证的一部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Discovery\n",
    "\n",
    "If you have used Kafka then you will be aware of the properties configuration and the adding of bootstrap servers, broker lists or Zookeeper nodes depending on the operation you are doing. When new brokers are added then properties need amending with the new addresses appended to the configuration.\\\n",
    "如果你使用过Kafka，那么你会注意到属性配置和添加bootstrap服务器，broker列表或Zookeeper节点，这取决于你正在做的操作。当添加新的broker时，属性需要通过添加到配置中的新地址进行修改。\n",
    "\n",
    "Pulsar provides a proxy layer to address the cluster with a single address. This is a huge advantage over Kafka especially when you are deploying with frameworks such as Kubernetes where direct access to the brokers is not possible. Another win is that you are allowed to run as many Pulsar proxies as you wish and they can be accessed via a single point with a load balancer. For cloud based deployments this makes managing and accessing the cluster easy.\\\n",
    "Pulsar提供一个proxy层来用一个单一的地址来寻址集群。与Kafka相比，这是一个巨大的优势，特别是当你使用Kubernetes这样的框架部署时，直接访问broker是不可能的。另一个优势是，你可以运行尽可能多的Pulsar proxy，它们可以通过一个负载均衡器通过一个单点访问。对于基于云的部署，这使得管理和访问集群变得很容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As message frequencies increase then there comes a time when you have to scale up the cluster to accommodate the volume of messages. With Kafka this means adding more brokers to the cluster. Adding new brokers to Kafka is not an easy task, this is something Pulsar is far superior to. With Kafka the broker is added to the cluster and then the manual process of repartitioning and replicating the message data to the new broker is done. Depending on the message volumes this can take a lot of time.\\\n",
    "随着消息频率的增加，您必须扩大集群以适应消息的数量。使用Kafka，这意味着向集群中添加更多的broker。添加新的broker到Kafka不是一个容易的任务，这是Pulsar远优于的事情。使用Kafka，broker被添加到集群中，然后手工的重新分区和复制消息数据到新的代理就完成了。根据消息量的不同，这可能会花费大量时间。\n",
    "\n",
    "Where Kafka uses the brokers for storage, Pulsar uses Apache Bookkeeper and not in the brokers themselves. The main difference is that Pulsar is storing unacknowledged messages, replication and separating the message persistence from the brokers.\\\n",
    "Kafka使用broker来存储，而Pulsar使用的是Apache Bookkeeper而不是代理本身。主要的区别是Pulsar存储未确认的消息、复制和将消息持久性从broker中分离出来。\n",
    "\n",
    "With Pulsar if you want to increase message capacity then you add as many Bookkeeper instances as you require without having to add the equivalent number of brokers (as you would with Kafka).\\\n",
    "对于Pulsar，如果你想增加消息容量，那么你就需要添加尽可能多的Bookkeeper实例，而不必添加相同数量的broker(就像你在Kafka中所做的那样)。\n",
    "\n",
    "Pulsar provides the option to use non persistent topics in memory, with no data being written to disk. Note however, if the Pulsar broker disconnects from the cluster then those messages and non persistent topics will be lost, whether it is stored in the broker or in transit to the consumer.\\\n",
    "Pulsar提供了在内存中使用非持久性主题的选项，不需要将数据写入磁盘。但是请注意，如果Pulsar代理与集群断开连接，那么这些消息和非持久性主题将会丢失，不管它们是存储在代理中还是传输到消费者中\n",
    "\n",
    "While there are various Kafka client libraries available it’s worth taking the time to study the Kafka features they support, not all aspects of the Kafka APIs are covered in the client libraries. For example if you want to handle Kafka’s Streaming API, only Java covers that API.\\\n",
    "虽然有各种各样的Kafka客户端库，但是值得花时间研究它们支持的Kafka特性，并不是Kafka api的所有方面都包含在客户端库中。例如，如果你想处理Kafka的流API，只有Java覆盖那个API。\n",
    "\n",
    "One of the interesting bonuses of the Pulsar client Java libraries is that they drop in to existing Kafka producer and consumer code. The only thing that you need to do is update the client dependency in Maven. This gives you an excellent way to evaluate Pulsar without having to refactor all your code.\\\n",
    "Pulsar客户端Java库的一个有趣的附加功能是，它们可以插入到现有的Kafka生产者和消费者代码中。您需要做的惟一一件事就是更新Maven中的客户机依赖项。这给了你一个很好的方法来评估Pulsar，而不必重构所有的代码。\n",
    "\n",
    "There are some differences between Pulsar and Kafka when it comes to reading messages. Kafka is an immutable log, with the offset controlling which is the latest message the consumer would read from. If you don’t want to get in the detail of committing your own offsets then you can let the Kafka client API do that for you.\\\n",
    "在阅读信息时，Pulsar和Kafka之间有一些区别。Kafka是一个不可变的日志，它的偏移量控制着消费者读取的最新消息。如果你不想进入提交你自己的补偿的细节，那么你可以让Kafka客户端API为你做这个。\n",
    "\n",
    "With Pulsar you have a choice of two consuming methods:\\\n",
    "对于Pulsar，有两种消费方式可供选择:\n",
    "* The consumer interface – this behaves in the same way as a Kafka consumer, reading the latest available message from the log.\\\n",
    "消费者接口——这与Kafka消费者的行为方式相同，从日志中读取最新的可用消息。\n",
    "* The reader interface – this enables the application to read a specific message regardless of ordering in the log.\\\n",
    "reader接口——允许应用程序读取特定消息，而不考虑日志中的排序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Persisting Data from External Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For anyone who remembers writing producers and consumers that handled database data, it was a difficult process and difficult to scale.\\\n",
    "对于那些还记得编写处理数据库数据的生产者和消费者的人来说，这是一个困难的过程，而且难以扩展。\n",
    "\n",
    "Within Kafka the Kafka Connect system provided a convenient method of either sourcing data to topics or persisting data to a sink.\\\n",
    "在Kafka中，Kafka Connect系统提供了一种方便的方法，既可以将数据源到主题，也可以将数据持久化到接收器。\n",
    "\n",
    "Apache Pulsar has a similar method called Pulsar IO. It has the same source/sink method of acquiring data or persisting it. The disadvantage here is the support for those external systems.\\\n",
    "Apache Pulsar也有类似的方法，叫做Pulsar IO。它具有相同的获取数据或持久化数据的source/sink方法。缺点是对那些外部系统的支持。\n",
    "\n",
    "For some systems such as Apache Cassandra, both systems are supported. If it’s JDBC operations that you want to do, once again both are supported well. Other open source systems like Flume, Debezium, Hadoop HDFS, Solr and ElasticSearch are supported by both systems. There are far more supported vendors for Kafka Connect than there are for Pulsar IO. While you can write your own plugins it is far easier to use an off the shelf one. In terms of connector availability Kafka Connect is an easy choice.\\\n",
    "对于某些系统（如Apache Cassandra），两种系统都支持。如果您想要执行的是JDBC操作，那么这两种操作都得到了很好的支持。其他的开源系统，如Flume, Debezium, Hadoop HDFS, Solr和ElasticSearch都支持这两个系统。Kafka Connect支持的供应商远远多于Pulsar IO支持的供应商。虽然您可以编写自己的插件，但使用现成的插件要容易得多。就连接器可用性而言，Kafka Connect是一个简单的选择。\n",
    "\n",
    "Please note that not all connectors for Kafka are free, some of them you will have to purchase with a licence from Confluent (the commercial arm of Kafka).\\\n",
    "请注意，并不是所有的Kafka连接器都是免费的，其中一些你需要从Confluent (Kafka的商业部门)购买许可。\n",
    "\n",
    "If the ease of availability and implementation is important to you then the Kafka connector support is far superior to the Pulsar option.\\\n",
    "如果易用性和实现对您来说很重要，那么Kafka连接器的支持要远远优于Pulsar选项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Type Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SQL like queries on message streams can speed up the development of basic applications and bypassing any code development being required. These SQL engines also make the use of aggregating data (counting frequencies of certain keys, averages and so on) very easy.\\\n",
    "在消息流上使用类似SQL的查询可以加快基本应用程序的开发，并绕过任何需要的代码开发。这些SQL引擎还使聚合数据的使用(计算某些键的频率、平均值等等)变得非常容易。\n",
    "\n",
    "There are SQL engines for both Kafka and Pulsar. The Kafka KSQL engine is a standalone product produced by Confluent and does not come with the Apache Kafka binaries. It is licenced under the Conflent Community Licence.\\\n",
    "Kafka和Pulsar都有SQL引擎。Kafka KSQL引擎是Confluent出品的独立产品，不附带Apache的Kafka二进制文件。它在Conflent社区许可证下获得许可。\n",
    "\n",
    "Apache Pulsar uses the Presto SQL engine to query messages with a schema stored in its schema register. Messages are required to be ingested first and then queried, where KSQL streams the data in the same way a Streaming API application would continuously run and apply the queries.\\\n",
    "Apache Pulsar使用Presto SQL引擎查询存储在其模式寄存器中的模式的消息。需要先接收消息，然后查询消息，其中KSQL以流API应用程序持续运行和应用查询的相同方式流数据。\n",
    "\n",
    "While there are a few issues with KSQL once you go beyond the basics, I prefer it over Pulsar’s read and then query mechanism.\\\n",
    "虽然KSQL有一些问题，一旦你超越了基本知识，我更喜欢它胜过Pulsar的读取然后查询机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Term Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to store old data beyond the retention period of the brokers is one that’s often overlooked. It has become more important as machine learning is being used on the data for recommendation systems, or replaying the data as a system of a record.\\\n",
    "将旧数据存储到超出broker保留期的能力常常被忽视。随着机器学习被用于推荐系统的数据上，或者作为一个记录系统来重放数据，它变得更加重要。\n",
    "\n",
    "Before Kafka Connect it was common for developers to write their own streaming jobs to persist to the likes of Amazon S3 or other types of storage buckets. Tiered storage appeared in Kafka only recently and is only available in the Confluent Kafka Platform 6.0.0 onwards as a paid for option. Persistence is to Amazon S3, Google Cloud Storage or Pure Storage FlashBlade.\\\n",
    "在Kafka Connect之前，对于开发者来说，写他们自己的流作业以持久化到Amazon S3或其他类型的存储桶是很常见的。分级存储最近才出现在Kafka中，并且只能在Confluent Kafka平台6.0.0之后作为付费选项使用。持久化是到Amazon S3，谷歌云存储或纯存储FlashBlade。\n",
    "\n",
    "Pulsar offers tiered storage as part of the open source distribution, using the Apache JCloud framework to store data to Amazon S3 or Google Cloud Storage, with other vendors planned for the future. The fact that the tiered storage is available for free and out of the box is a huge advantage for Pulsar against Kafka.\\\n",
    "Pulsar提供分层存储作为开源发行版的一部分，使用Apache JCloud框架将数据存储到Amazon S3或谷歌云存储中，其他供应商也计划在未来提供分层存储。事实上，与Kafka相比，Pulsar的分层存储是免费和开箱即用的，这是一个巨大的优势。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
